{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShuffleNetV2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov7EmHf4i2xO",
        "colab_type": "text"
      },
      "source": [
        "model.cifar.vgg-cfiar.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHMv_34RP2nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "fd14b5d6-8847-4632-dd26-06f250ea9dda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3myjfvr73BV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7e820ce0-c954-46af-8b11-ead45a27577b"
      },
      "source": [
        "!pip install thop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/de/dc/8ca7381a90a79fecc85f9c9e3e3914865067561c6b1b56f201f97842255e/thop-0.0.31.post2001170342-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from thop) (1.4.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.0.31.post2001170342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiayO0oitI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    'ShuffleNetV2', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0',\n",
        "    'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0'\n",
        "]\n",
        "\n",
        "model_urls = {\n",
        "    'shufflenetv2_x0.5': 'https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth',\n",
        "    'shufflenetv2_x1.0': 'https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth',\n",
        "    'shufflenetv2_x1.5': None,\n",
        "    'shufflenetv2_x2.0': None,\n",
        "}\n",
        "\n",
        "\n",
        "def channel_shuffle(x, groups):\n",
        "    # type: (torch.Tensor, int) -> torch.Tensor\n",
        "    batchsize, num_channels, height, width = x.data.size()\n",
        "    channels_per_group = num_channels // groups\n",
        "\n",
        "    # reshape\n",
        "    x = x.view(batchsize, groups,\n",
        "               channels_per_group, height, width)\n",
        "\n",
        "    x = torch.transpose(x, 1, 2).contiguous()\n",
        "\n",
        "    # flatten\n",
        "    x = x.view(batchsize, -1, height, width)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "\n",
        "        if not (1 <= stride <= 3):\n",
        "            raise ValueError('illegal stride value')\n",
        "        self.stride = stride\n",
        "\n",
        "        branch_features = oup // 2\n",
        "        assert (self.stride != 1) or (inp == branch_features << 1)\n",
        "\n",
        "        if self.stride > 1:\n",
        "            self.branch1 = nn.Sequential(\n",
        "                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(branch_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            self.branch1 = nn.Sequential()\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(inp if (self.stride > 1) else branch_features,\n",
        "                      branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(branch_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),\n",
        "            nn.BatchNorm2d(branch_features),\n",
        "            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(branch_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def depthwise_conv(i, o, kernel_size, stride=1, padding=0, bias=False):\n",
        "        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.stride == 1:\n",
        "            x1, x2 = x.chunk(2, dim=1)\n",
        "            out = torch.cat((x1, self.branch2(x2)), dim=1)\n",
        "        else:\n",
        "            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)\n",
        "\n",
        "        out = channel_shuffle(out, 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ShuffleNetV2(nn.Module):\n",
        "    def __init__(self, stages_repeats, stages_out_channels, num_classes=100, inverted_residual=InvertedResidual):\n",
        "        super(ShuffleNetV2, self).__init__()\n",
        "\n",
        "        if len(stages_repeats) != 3:\n",
        "            raise ValueError('expected stages_repeats as list of 3 positive ints')\n",
        "        if len(stages_out_channels) != 5:\n",
        "            raise ValueError('expected stages_out_channels as list of 5 positive ints')\n",
        "        self._stage_out_channels = stages_out_channels\n",
        "\n",
        "        input_channels = 3\n",
        "        output_channels = self._stage_out_channels[0]\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        input_channels = output_channels\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        stage_names = ['stage{}'.format(i) for i in [2, 3, 4]]\n",
        "        for name, repeats, output_channels in zip(\n",
        "                stage_names, stages_repeats, self._stage_out_channels[1:]):\n",
        "            seq = [inverted_residual(input_channels, output_channels, 2)]\n",
        "            for i in range(repeats - 1):\n",
        "                seq.append(inverted_residual(output_channels, output_channels, 1))\n",
        "            setattr(self, name, nn.Sequential(*seq))\n",
        "            input_channels = output_channels\n",
        "\n",
        "        output_channels = self._stage_out_channels[-1]\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(output_channels, num_classes)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = x.mean([2, 3])  # globalpool\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _shufflenetv2(arch, pretrained, progress, *args, **kwargs):\n",
        "    model = ShuffleNetV2(*args, **kwargs)\n",
        "\n",
        "    if pretrained:\n",
        "        model_url = model_urls[arch]\n",
        "        if model_url is None:\n",
        "            raise NotImplementedError('pretrained {} is not supported as of now'.format(arch))\n",
        "        else:\n",
        "            state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
        "            model.load_state_dict(state_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def shufflenet_v2_x0_5(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ShuffleNetV2 with 0.5x output channels, as described in\n",
        "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
        "    <https://arxiv.org/abs/1807.11164>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _shufflenetv2('shufflenetv2_x0.5', pretrained, progress,\n",
        "                         [4, 8, 4], [24, 48, 96, 192, 1024], **kwargs)\n",
        "\n",
        "\n",
        "def shufflenet_v2_x1_0(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ShuffleNetV2 with 1.0x output channels, as described in\n",
        "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
        "    <https://arxiv.org/abs/1807.11164>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _shufflenetv2('shufflenetv2_x1.0', pretrained, progress,\n",
        "                         [4, 8, 4], [24, 116, 232, 464, 1024], **kwargs)\n",
        "\n",
        "\n",
        "def shufflenet_v2_x1_5(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ShuffleNetV2 with 1.5x output channels, as described in\n",
        "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
        "    <https://arxiv.org/abs/1807.11164>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _shufflenetv2('shufflenetv2_x1.5', pretrained, progress,\n",
        "                         [4, 8, 4], [24, 176, 352, 704, 1024], **kwargs)\n",
        "\n",
        "\n",
        "def shufflenet_v2_x2_0(pretrained=False, progress=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a ShuffleNetV2 with 2.0x output channels, as described in\n",
        "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
        "    <https://arxiv.org/abs/1807.11164>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _shufflenetv2('shufflenetv2_x2.0', pretrained, progress,\n",
        "                         [4, 8, 4], [24, 244, 488, 976, 2048], **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDTTk-VsjAPS",
        "colab_type": "text"
      },
      "source": [
        "config.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxauZ6_XimSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import easydict\n",
        "\n",
        "\n",
        "def config():\n",
        "  \n",
        "    cfg = easydict.EasyDict({\n",
        "            \"arch\": \"shufflenetv2\",\n",
        "            \"dataset\": \"cifar100\",\n",
        "            \"batch_size\": 128,\n",
        "            \"epochs\": 100,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"weight_decay\": 0.00001,\n",
        "            \"momentum\": 0.9,\n",
        "            \"nesterov\": True,\n",
        "            \"print_freq\": 50,\n",
        "            \"ckpt\": \"/content/drive/My Drive/MLVC/Baseline/checkpoint/\",\n",
        "            \"results_dir\": \"./results/\",\n",
        "            \"resume\": False,\n",
        "            \"evaluate\": False,\n",
        "            \"cuda\": True,\n",
        "            \"gpuids\": [0],\n",
        "            \"colab\": True,    \n",
        "    })\n",
        "\n",
        "\n",
        "    cfg.gpuids = list(map(int, cfg.gpuids))\n",
        "\n",
        "    model = shufflenet_v2_x1_0()\n",
        "    if cfg.arch == \"shufflenetv2\":\n",
        "        model = shufflenet_v2_x1_0()\n",
        "    #elif cfg.arch == \"resnet-cifar\":\n",
        "    #    model = resnet.resnet20()\n",
        "    #elif cfg.arch == \"vgg-cifar-binary\":\n",
        "    #    model = vgg_bnn.vgg11()\n",
        "    #elif cfg.arch == \"resnet-cifar-dorefa\":\n",
        "    #    model = resnet_dorefanet.resnet20()\n",
        "\n",
        "    return cfg, model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uijg3T_jKpH",
        "colab_type": "text"
      },
      "source": [
        "utility.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAxpnTajMvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def load_model(model, ckpt_file, args):\n",
        "    if args.cuda:\n",
        "        checkpoint = torch.load(\n",
        "            ckpt_file, map_location=lambda storage, loc: storage.cuda(args.gpuids[0])\n",
        "        )\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            model.module.load_state_dict(checkpoint[\"model\"])\n",
        "    else:\n",
        "        checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            # create new OrderedDict that does not contain `module.`\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in checkpoint[\"model\"].items():\n",
        "                if k[:7] == \"module.\":\n",
        "                    name = k[7:]  # remove `module.`\n",
        "                else:\n",
        "                    name = k[:]\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "            model.load_state_dict(new_state_dict)\n",
        "\n",
        "    return checkpoint\n",
        "\n",
        "\n",
        "def save_model(state, epoch, is_best, args):\n",
        "    dir_ckpt = pathlib.Path(\"checkpoint\")\n",
        "    dir_path = dir_ckpt / args.dataset\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model_file = dir_path / \"ckpt_epoch_{}.pth\".format(epoch)\n",
        "    torch.save(state, model_file)\n",
        "\n",
        "    if is_best:\n",
        "        shutil.copyfile(model_file, dir_path / \"ckpt_best.pth\")\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=\":f\"):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print(\"\\t\".join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
        "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr):\n",
        "    \"\"\"Sets the learning rate, decayed rate of 0.1 every epoch\"\"\"\n",
        "    if epoch >= 50:\n",
        "        lr = 0.01\n",
        "    if epoch >= 75:\n",
        "        lr = 0.001\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "    return lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def print_reults(start_time, train_time, validate_time, start_epoch, epochs):\n",
        "    avg_train_time = train_time / (epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600), int((elapsed_time % 3600) // 60), elapsed_time % 60\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NYZJ-dXjZLX",
        "colab_type": "text"
      },
      "source": [
        "data_loader.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHxY6xojjcH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "def dataloader(dataset, batch_size):\n",
        "    train_dataset, val_dataset = load_cifar100()\n",
        "\n",
        "    if dataset == \"CIFAR100\":\n",
        "        train_dataset, val_dataset = load_cifar100()\n",
        "\n",
        "    # Data loader\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def load_cifar10():\n",
        "    # CIFAR-10 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def load_cifar100():\n",
        "    # CIFAR-100 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "    train_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY8Jl99qjgEL",
        "colab_type": "text"
      },
      "source": [
        "main.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4lPApbXhvVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "df20a7fd-d1c0-4efe-c4b9-febf311a5d35"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import time\n",
        "import pathlib\n",
        "from os.path import isfile\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, start_epoch, best_acc1\n",
        "    args, model = config()\n",
        "\n",
        "    print(\"Model: {}\".format(args.arch))\n",
        "    \n",
        "    from thop import profile\n",
        "    input = torch.randn(1, 3, 32, 32)\n",
        "    flops, params = profile(model, inputs=(input, ))\n",
        "    from thop import clever_format\n",
        "    macs, params = clever_format([flops, params], \"%.3f\")\n",
        "    print(\"MACS: {}\".format(macs))\n",
        "    print(\"Params: {}\".format(params))\n",
        "\n",
        "    if args.cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        momentum=args.momentum,\n",
        "        nesterov=args.nesterov,\n",
        "    )\n",
        "\n",
        "    best_acc1 = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if args.cuda:\n",
        "        torch.cuda.set_device(args.gpuids[0])\n",
        "        with torch.cuda.device(args.gpuids[0]):\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "        model = nn.DataParallel(\n",
        "            model, device_ids=args.gpuids, output_device=args.gpuids[0]\n",
        "        )\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    # checkpoint file\n",
        "    ckpt_dir = pathlib.Path(args.ckpt)\n",
        "    ckpt_file = ckpt_dir / args.dataset / args.ckpt\n",
        "\n",
        "    # for resuming training\n",
        "    if args.resume:\n",
        "        retrain(ckpt_file, model, optimizer)\n",
        "\n",
        "    # Data loading\n",
        "    print(\"\\n==> Load data..\")\n",
        "    train_loader, val_loader = dataloader(args.dataset, args.batch_size)\n",
        "\n",
        "    # initiailizae\n",
        "    train_time, validate_time = 0.0, 0.0\n",
        "    avgloss_train = 0.0\n",
        "    acc1_train, acc5_train, acc1_valid, acc5_valid = 0.0, 0.0, 0.0, 0.0\n",
        "    is_best = False\n",
        "\n",
        "    # result lists\n",
        "    result_epoch, result_lr, result_train_avgtime, result_train_avgloss = [], [], [], []\n",
        "    result_train_avgtop1acc, result_train_avgtop5acc = [], []\n",
        "    result_val_avgtime, result_val_avgtop1acc, result_val_avgtop5acc = [], [], []\n",
        "\n",
        "    # train...\n",
        "    lr = args.learning_rate\n",
        "    curr_lr = lr\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        curr_lr = adjust_learning_rate(optimizer, epoch, lr)\n",
        "        print(\"\\n==> Epoch: {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "        # train for one epoch\n",
        "        train_time, acc1_train, acc5_train, avgloss_train = train_epoch(\n",
        "            train_time,\n",
        "            acc1_train,\n",
        "            acc5_train,\n",
        "            avgloss_train,\n",
        "            train_loader,\n",
        "            epoch,\n",
        "            model,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "        )\n",
        "\n",
        "        # evaluate on validation set\n",
        "        validate_time, acc1_valid, acc5_valid = validation_epoch(\n",
        "            validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "        )\n",
        "\n",
        "        # remember best Acc@1 and save checkpoint\n",
        "        is_best = save_model_data(\n",
        "            is_best, best_acc1, acc1_valid, epoch, model, optimizer, args\n",
        "        )\n",
        "\n",
        "\n",
        "        result_epoch.append(epoch)\n",
        "        result_lr.append(curr_lr)\n",
        "        result_train_avgtime.append(train_time)\n",
        "        result_train_avgloss.append(avgloss_train)\n",
        "        result_train_avgtop1acc.append(acc1_train.item())\n",
        "        result_train_avgtop5acc.append(acc5_train.item())\n",
        "        result_val_avgtop1acc.append(acc1_valid.item())\n",
        "        result_val_avgtop5acc.append(acc5_valid.item())\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Epoch': result_epoch,\n",
        "            'Learning rate': result_lr,\n",
        "            'Training avg loss': result_train_avgloss,\n",
        "            'Training avg top1 acc': result_train_avgtop1acc,\n",
        "            'Training avg top5 acc': result_train_avgtop5acc,\n",
        "            'Test avg top1 acc': result_val_avgtop1acc,\n",
        "            'Test avg top5 acc': result_val_avgtop5acc,\n",
        "        })\n",
        "\n",
        "        if args.colab:\n",
        "            df.to_csv('/content/drive/My Drive/MLVC/Baseline/results/{}_result.csv'.format(args.arch))\n",
        "        else:\n",
        "            df.to_csv('./results/{}_result.csv'.format(args.arch))\n",
        "\n",
        "\n",
        "    print_results(train_time, validate_time)\n",
        "\n",
        "\n",
        "def retrain(ckpt_file, model, optimizer):\n",
        "    if isfile(ckpt_file):\n",
        "        print(\"\\n==> Loading Checkpoint '{}'\".format(args.ckpt))\n",
        "        checkpoint = load_model(model, ckpt_file, args)\n",
        "\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "        print(\"==> Loaded Checkpoint '{}' (epoch {})\".format(args.ckpt, start_epoch))\n",
        "    else:\n",
        "        print(\"==> no checkpoint found '{}'\".format(args.ckpt))\n",
        "        return\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    train_time, acc1_train, acc5_train, avgloss_train, train_loader, epoch, model, criterion, optimizer\n",
        "):\n",
        "    print(\"===> [ Training ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_train, acc5_train, avgloss_train = train(\n",
        "        train_loader, epoch=epoch, model=model, criterion=criterion, optimizer=optimizer\n",
        "    )\n",
        "    elapsed_time = time.time() - start_time\n",
        "    train_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to train this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return train_time, acc1_train, acc5_train, avgloss_train\n",
        "\n",
        "\n",
        "def validation_epoch(\n",
        "    validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "):\n",
        "    print(\"===> [ Validation ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_valid, acc5_valid, avgloss_valid = validate(val_loader, model, criterion)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    validate_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to validate this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return validate_time, acc1_valid, acc5_valid\n",
        "\n",
        "\n",
        "def save_model_data(is_best, best_acc1, acc1_valid, epoch, model, optimizer, args):\n",
        "    is_best = acc1_valid > best_acc1\n",
        "    best_acc1 = max(acc1_valid, best_acc1)\n",
        "    state = {\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        save_model(state, epoch, is_best, args)\n",
        "    return is_best\n",
        "\n",
        "\n",
        "def train(train_loader, **kwargs):\n",
        "    epoch = kwargs.get(\"epoch\")\n",
        "    model = kwargs.get(\"model\")\n",
        "    criterion = kwargs.get(\"criterion\")\n",
        "    optimizer = kwargs.get(\"optimizer\")\n",
        "\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        batch_time,\n",
        "        data_time,\n",
        "        losses,\n",
        "        top1,\n",
        "        top5,\n",
        "        prefix=\"Epoch: [{}]\".format(epoch),\n",
        "    )\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.cuda:\n",
        "            input = input.cuda(non_blocking=True)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0], input.size(0))\n",
        "        top5.update(acc5[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "    print(\n",
        "        \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(top1=top1, top5=top5)\n",
        "    )\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(\"====> Epoch loss {:.3f}\".format(epoch_loss))\n",
        "\n",
        "    return top1.avg, top5.avg, epoch_loss\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader), batch_time, losses, top1, top5, prefix=\"Test: \"\n",
        "    )\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            if args.cuda:\n",
        "                input = input.cuda(non_blocking=True)\n",
        "                target = target.cuda(non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(acc1[0], input.size(0))\n",
        "            top5.update(acc5[0], input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.print(i)\n",
        "\n",
        "            end = time.time()\n",
        "\n",
        "        print(\n",
        "            \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(\n",
        "                top1=top1, top5=top5\n",
        "            )\n",
        "        )\n",
        "        total_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return top1.avg, top5.avg, loss.item()\n",
        "\n",
        "\n",
        "def print_results(train_time, validate_time):\n",
        "\n",
        "    avg_train_time = train_time / (args.epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (args.epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    main()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600),\n",
        "            int((elapsed_time % 3600) // 60),\n",
        "            elapsed_time % 60,\n",
        "        )\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: shufflenetv2\n",
            "MACS: 3.221M\n",
            "Params: 1.356M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-52cf5e52b240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     print(\n",
            "\u001b[0;32m<ipython-input-7-52cf5e52b240>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         model = nn.DataParallel(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}