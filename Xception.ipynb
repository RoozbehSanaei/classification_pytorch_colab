{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov7EmHf4i2xO",
        "colab_type": "text"
      },
      "source": [
        "model.cifar.vgg-cfiar.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHMv_34RP2nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7ff7718-f029-4069-fde8-8714c6748ef3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiayO0oitI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=1)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Xception, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=1, stride=2)\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            SeparableConv2d(64, 128, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(128, 128, 3),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=1, stride=2)\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(128, 256, kernel_size=3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(256, 256, 3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 728, kernel_size=1, stride=2)\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(256, 728, kernel_size=3),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 728, 3),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Conv2d(728, 728, kernel_size=1, stride=2)\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 728, kernel_size=3),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 728, 3),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 728, 3),\n",
        "            nn.BatchNorm2d(728),  \n",
        "        )\n",
        "\n",
        "        self.conv7 = nn.Conv2d(728, 1024, kernel_size=1, stride=2)\n",
        "\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 728, kernel_size=3),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(728, 1024, 3),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)   \n",
        "        )\n",
        "\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(1024, 1536, kernel_size=3),\n",
        "            nn.BatchNorm2d(1536),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv2d(1536, 2048, 3),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.AvgPool2d(kernel_size=1, stride=1)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(2048, 100)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "\n",
        "        x = self.block1(x) + self.conv3(x)\n",
        "        x = self.block2(x) + self.conv4(x)\n",
        "        x = self.block3(x) + self.conv5(x)\n",
        "        x = self.block4(x) + self.conv6(x)\n",
        "        x = self.block5(x) + self.conv7(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def xception():\n",
        "    return Xception()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDTTk-VsjAPS",
        "colab_type": "text"
      },
      "source": [
        "config.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxauZ6_XimSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import easydict\n",
        "\n",
        "\n",
        "def config():\n",
        "  \n",
        "    cfg = easydict.EasyDict({\n",
        "            \"arch\": \"xception\",\n",
        "            \"dataset\": \"cifar100\",\n",
        "            \"batch_size\": 128,\n",
        "            \"epochs\": 200,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"weight_decay\": 0.00001,\n",
        "            \"momentum\": 0.9,\n",
        "            \"nesterov\": True,\n",
        "            \"print_freq\": 50,\n",
        "            \"ckpt\": \"/content/drive/My Drive/MLVC/Baseline/checkpoint/\",\n",
        "            \"results_dir\": \"./results/\",\n",
        "            \"resume\": False,\n",
        "            \"evaluate\": False,\n",
        "            \"cuda\": True,\n",
        "            \"gpuids\": [0],\n",
        "            \"colab\": True,    \n",
        "    })\n",
        "\n",
        "\n",
        "    cfg.gpuids = list(map(int, cfg.gpuids))\n",
        "\n",
        "    model = xception()\n",
        "    if cfg.arch == \"xception\":\n",
        "        model = xception()\n",
        "    #elif cfg.arch == \"resnet-cifar\":\n",
        "    #    model = resnet.resnet20()\n",
        "    #elif cfg.arch == \"vgg-cifar-binary\":\n",
        "    #    model = vgg_bnn.vgg11()\n",
        "    #elif cfg.arch == \"resnet-cifar-dorefa\":\n",
        "    #    model = resnet_dorefanet.resnet20()\n",
        "\n",
        "    return cfg, model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uijg3T_jKpH",
        "colab_type": "text"
      },
      "source": [
        "utility.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAxpnTajMvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def load_model(model, ckpt_file, args):\n",
        "    if args.cuda:\n",
        "        checkpoint = torch.load(\n",
        "            ckpt_file, map_location=lambda storage, loc: storage.cuda(args.gpuids[0])\n",
        "        )\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            model.module.load_state_dict(checkpoint[\"model\"])\n",
        "    else:\n",
        "        checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            # create new OrderedDict that does not contain `module.`\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in checkpoint[\"model\"].items():\n",
        "                if k[:7] == \"module.\":\n",
        "                    name = k[7:]  # remove `module.`\n",
        "                else:\n",
        "                    name = k[:]\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "            model.load_state_dict(new_state_dict)\n",
        "\n",
        "    return checkpoint\n",
        "\n",
        "\n",
        "def save_model(state, epoch, is_best, args):\n",
        "    dir_ckpt = pathlib.Path(\"checkpoint\")\n",
        "    dir_path = dir_ckpt / args.dataset\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model_file = dir_path / \"ckpt_epoch_{}.pth\".format(epoch)\n",
        "    torch.save(state, model_file)\n",
        "\n",
        "    if is_best:\n",
        "        shutil.copyfile(model_file, dir_path / \"ckpt_best.pth\")\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=\":f\"):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print(\"\\t\".join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
        "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr):\n",
        "    \"\"\"Sets the learning rate, decayed rate of 0.1 every epoch\"\"\"\n",
        "    #if epoch >= 60:\n",
        "    #    lr = 0.01\n",
        "    #if epoch >= 120:\n",
        "    #    lr = 0.001\n",
        "    #if epoch >= 160:\n",
        "    #    lr = 0.0001\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "    return lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def print_reults(start_time, train_time, validate_time, start_epoch, epochs):\n",
        "    avg_train_time = train_time / (epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600), int((elapsed_time % 3600) // 60), elapsed_time % 60\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NYZJ-dXjZLX",
        "colab_type": "text"
      },
      "source": [
        "data_loader.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHxY6xojjcH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "def dataloader(dataset, batch_size):\n",
        "    train_dataset, val_dataset = load_cifar10()\n",
        "\n",
        "    if dataset == \"cifar100\":\n",
        "        train_dataset, val_dataset = load_cifar100()\n",
        "\n",
        "    # Data loader\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def load_cifar10():\n",
        "    # CIFAR-10 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def load_cifar100():\n",
        "    # CIFAR-100 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "    train_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY8Jl99qjgEL",
        "colab_type": "text"
      },
      "source": [
        "main.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4lPApbXhvVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "725f7945-2ce4-4674-f65c-9a5d9410c16f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import time\n",
        "import pathlib\n",
        "from os.path import isfile\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, start_epoch, best_acc1\n",
        "    args, model = config()\n",
        "\n",
        "    print(\"Model: {}\".format(args.arch))\n",
        "\n",
        "    if args.cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        momentum=args.momentum,\n",
        "        nesterov=args.nesterov,\n",
        "    )\n",
        "\n",
        "    best_acc1 = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if args.cuda:\n",
        "        torch.cuda.set_device(args.gpuids[0])\n",
        "        with torch.cuda.device(args.gpuids[0]):\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "        model = nn.DataParallel(\n",
        "            model, device_ids=args.gpuids, output_device=args.gpuids[0]\n",
        "        )\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    # checkpoint file\n",
        "    ckpt_dir = pathlib.Path(args.ckpt)\n",
        "    ckpt_file = ckpt_dir / args.dataset / args.ckpt\n",
        "\n",
        "    # for resuming training\n",
        "    if args.resume:\n",
        "        retrain(ckpt_file, model, optimizer)\n",
        "\n",
        "    # Data loading\n",
        "    print(\"\\n==> Load data..\")\n",
        "    train_loader, val_loader = dataloader(args.dataset, args.batch_size)\n",
        "\n",
        "    # initiailizae\n",
        "    train_time, validate_time = 0.0, 0.0\n",
        "    avgloss_train = 0.0\n",
        "    acc1_train, acc5_train, acc1_valid, acc5_valid = 0.0, 0.0, 0.0, 0.0\n",
        "    is_best = False\n",
        "\n",
        "    # result lists\n",
        "    result_epoch, result_lr, result_train_avgtime, result_train_avgloss = [], [], [], []\n",
        "    result_train_avgtop1acc, result_train_avgtop5acc = [], []\n",
        "    result_val_avgtime, result_val_avgtop1acc, result_val_avgtop5acc = [], [], []\n",
        "\n",
        "    # train...\n",
        "    lr = args.learning_rate\n",
        "    curr_lr = lr\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        curr_lr = adjust_learning_rate(optimizer, epoch, lr)\n",
        "        print(\"\\n==> Epoch: {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "        # train for one epoch\n",
        "        train_time, acc1_train, acc5_train, avgloss_train = train_epoch(\n",
        "            train_time,\n",
        "            acc1_train,\n",
        "            acc5_train,\n",
        "            avgloss_train,\n",
        "            train_loader,\n",
        "            epoch,\n",
        "            model,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "        )\n",
        "\n",
        "        # evaluate on validation set\n",
        "        validate_time, acc1_valid, acc5_valid = validation_epoch(\n",
        "            validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "        )\n",
        "\n",
        "        # remember best Acc@1 and save checkpoint\n",
        "        is_best = save_model_data(\n",
        "            is_best, best_acc1, acc1_valid, epoch, model, optimizer, args\n",
        "        )\n",
        "\n",
        "\n",
        "        result_epoch.append(epoch)\n",
        "        result_lr.append(curr_lr)\n",
        "        result_train_avgtime.append(train_time)\n",
        "        result_train_avgloss.append(avgloss_train)\n",
        "        result_train_avgtop1acc.append(acc1_train.item())\n",
        "        result_train_avgtop5acc.append(acc5_train.item())\n",
        "        result_val_avgtop1acc.append(acc1_valid.item())\n",
        "        result_val_avgtop5acc.append(acc5_valid.item())\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Epoch': result_epoch,\n",
        "            'Learning rate': result_lr,\n",
        "            'Training avg loss': result_train_avgloss,\n",
        "            'Training avg top1 acc': result_train_avgtop1acc,\n",
        "            'Training avg top5 acc': result_train_avgtop5acc,\n",
        "            'Test avg top1 acc': result_val_avgtop1acc,\n",
        "            'Test avg top5 acc': result_val_avgtop5acc,\n",
        "        })\n",
        "\n",
        "        if args.colab:\n",
        "            df.to_csv('/content/drive/My Drive/MLVC/Baseline/results/{}_result.csv'.format(args.arch))\n",
        "        else:\n",
        "            df.to_csv('./results/{}_result.csv'.format(args.arch))\n",
        "\n",
        "\n",
        "    print_results(train_time, validate_time)\n",
        "\n",
        "\n",
        "def retrain(ckpt_file, model, optimizer):\n",
        "    if isfile(ckpt_file):\n",
        "        print(\"\\n==> Loading Checkpoint '{}'\".format(args.ckpt))\n",
        "        checkpoint = load_model(model, ckpt_file, args)\n",
        "\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "        print(\"==> Loaded Checkpoint '{}' (epoch {})\".format(args.ckpt, start_epoch))\n",
        "    else:\n",
        "        print(\"==> no checkpoint found '{}'\".format(args.ckpt))\n",
        "        return\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    train_time, acc1_train, acc5_train, avgloss_train, train_loader, epoch, model, criterion, optimizer\n",
        "):\n",
        "    print(\"===> [ Training ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_train, acc5_train, avgloss_train = train(\n",
        "        train_loader, epoch=epoch, model=model, criterion=criterion, optimizer=optimizer\n",
        "    )\n",
        "    elapsed_time = time.time() - start_time\n",
        "    train_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to train this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return train_time, acc1_train, acc5_train, avgloss_train\n",
        "\n",
        "\n",
        "def validation_epoch(\n",
        "    validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "):\n",
        "    print(\"===> [ Validation ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_valid, acc5_valid, avgloss_valid = validate(val_loader, model, criterion)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    validate_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to validate this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return validate_time, acc1_valid, acc5_valid\n",
        "\n",
        "\n",
        "def save_model_data(is_best, best_acc1, acc1_valid, epoch, model, optimizer, args):\n",
        "    is_best = acc1_valid > best_acc1\n",
        "    best_acc1 = max(acc1_valid, best_acc1)\n",
        "    state = {\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        save_model(state, epoch, is_best, args)\n",
        "    return is_best\n",
        "\n",
        "\n",
        "def train(train_loader, **kwargs):\n",
        "    epoch = kwargs.get(\"epoch\")\n",
        "    model = kwargs.get(\"model\")\n",
        "    criterion = kwargs.get(\"criterion\")\n",
        "    optimizer = kwargs.get(\"optimizer\")\n",
        "\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        batch_time,\n",
        "        data_time,\n",
        "        losses,\n",
        "        top1,\n",
        "        top5,\n",
        "        prefix=\"Epoch: [{}]\".format(epoch),\n",
        "    )\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.cuda:\n",
        "            input = input.cuda(non_blocking=True)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0], input.size(0))\n",
        "        top5.update(acc5[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "    print(\n",
        "        \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(top1=top1, top5=top5)\n",
        "    )\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(\"====> Epoch loss {:.3f}\".format(epoch_loss))\n",
        "\n",
        "    return top1.avg, top5.avg, epoch_loss\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader), batch_time, losses, top1, top5, prefix=\"Test: \"\n",
        "    )\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            if args.cuda:\n",
        "                input = input.cuda(non_blocking=True)\n",
        "                target = target.cuda(non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(acc1[0], input.size(0))\n",
        "            top5.update(acc5[0], input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.print(i)\n",
        "\n",
        "            end = time.time()\n",
        "\n",
        "        print(\n",
        "            \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(\n",
        "                top1=top1, top5=top5\n",
        "            )\n",
        "        )\n",
        "        total_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return top1.avg, top5.avg, loss.item()\n",
        "\n",
        "\n",
        "def print_results(train_time, validate_time):\n",
        "\n",
        "    avg_train_time = train_time / (args.epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (args.epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    main()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600),\n",
        "            int((elapsed_time % 3600) // 60),\n",
        "            elapsed_time % 60,\n",
        "        )\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: xception\n",
            "\n",
            "==> Load data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "==> Epoch: 0, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [0][  0/391]\tTime  0.085 ( 0.085)\tData  0.030 ( 0.030)\tLoss 4.6868e+00 (4.6868e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   5.47 (  5.47)\n",
            "Epoch: [0][ 50/391]\tTime  0.087 ( 0.074)\tData  0.038 ( 0.028)\tLoss 1.4095e+01 (2.2584e+01)\tAcc@1   0.78 (  1.15)\tAcc@5   2.34 (  5.30)\n",
            "Epoch: [0][100/391]\tTime  0.090 ( 0.073)\tData  0.040 ( 0.028)\tLoss 5.1486e+00 (1.5213e+01)\tAcc@1   0.00 (  1.11)\tAcc@5   6.25 (  5.10)\n",
            "Epoch: [0][150/391]\tTime  0.071 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.6776e+00 (1.1855e+01)\tAcc@1   0.00 (  1.12)\tAcc@5   2.34 (  5.27)\n",
            "Epoch: [0][200/391]\tTime  0.066 ( 0.073)\tData  0.023 ( 0.028)\tLoss 4.8289e+00 (1.0085e+01)\tAcc@1   0.78 (  1.04)\tAcc@5   4.69 (  5.27)\n",
            "Epoch: [0][250/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.6382e+00 (9.0025e+00)\tAcc@1   3.91 (  1.03)\tAcc@5   4.69 (  5.33)\n",
            "Epoch: [0][300/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.6587e+00 (8.2763e+00)\tAcc@1   1.56 (  1.07)\tAcc@5  10.16 (  5.52)\n",
            "Epoch: [0][350/391]\tTime  0.090 ( 0.073)\tData  0.040 ( 0.027)\tLoss 4.6860e+00 (7.7552e+00)\tAcc@1   1.56 (  1.09)\tAcc@5   8.59 (  5.62)\n",
            "====> Acc@1 1.088 Acc@5 5.732\n",
            "====> Epoch loss 7.432\n",
            "====> 67.55 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.051 ( 0.051)\tLoss 4.6557e+00 (4.6557e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   7.81 (  7.81)\n",
            "Test: [50/79]\tTime  0.064 ( 0.054)\tLoss 4.6618e+00 (4.6369e+00)\tAcc@1   0.78 (  1.52)\tAcc@5   5.47 (  6.40)\n",
            "====> Acc@1 1.440 Acc@5 6.470\n",
            "====> 4.20 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 1, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [1][  0/391]\tTime  0.069 ( 0.069)\tData  0.025 ( 0.025)\tLoss 4.5129e+00 (4.5129e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   7.03 (  7.03)\n",
            "Epoch: [1][ 50/391]\tTime  0.067 ( 0.072)\tData  0.023 ( 0.027)\tLoss 4.5810e+00 (4.5907e+00)\tAcc@1   2.34 (  1.61)\tAcc@5  11.72 (  7.75)\n",
            "Epoch: [1][100/391]\tTime  0.072 ( 0.072)\tData  0.023 ( 0.026)\tLoss 4.5480e+00 (4.5729e+00)\tAcc@1   1.56 (  1.58)\tAcc@5   5.47 (  7.74)\n",
            "Epoch: [1][150/391]\tTime  0.066 ( 0.073)\tData  0.024 ( 0.027)\tLoss 4.6370e+00 (4.5693e+00)\tAcc@1   2.34 (  1.66)\tAcc@5   8.59 (  7.82)\n",
            "Epoch: [1][200/391]\tTime  0.070 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.4944e+00 (4.5646e+00)\tAcc@1   2.34 (  1.64)\tAcc@5  10.94 (  7.81)\n",
            "Epoch: [1][250/391]\tTime  0.067 ( 0.073)\tData  0.024 ( 0.027)\tLoss 4.5226e+00 (4.5586e+00)\tAcc@1   0.78 (  1.70)\tAcc@5   7.03 (  7.94)\n",
            "Epoch: [1][300/391]\tTime  0.071 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.5412e+00 (4.5533e+00)\tAcc@1   0.78 (  1.69)\tAcc@5   4.69 (  8.02)\n",
            "Epoch: [1][350/391]\tTime  0.071 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.4741e+00 (4.5468e+00)\tAcc@1   3.91 (  1.69)\tAcc@5  10.16 (  8.16)\n",
            "====> Acc@1 1.712 Acc@5 8.308\n",
            "====> Epoch loss 4.540\n",
            "====> 67.70 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.062 ( 0.062)\tLoss 4.5478e+00 (4.5478e+00)\tAcc@1   0.78 (  0.78)\tAcc@5  12.50 ( 12.50)\n",
            "Test: [50/79]\tTime  0.055 ( 0.054)\tLoss 4.4787e+00 (4.5090e+00)\tAcc@1   0.78 (  1.76)\tAcc@5  11.72 (  8.76)\n",
            "====> Acc@1 1.860 Acc@5 8.690\n",
            "====> 4.22 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 2, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [2][  0/391]\tTime  0.077 ( 0.077)\tData  0.029 ( 0.029)\tLoss 4.5103e+00 (4.5103e+00)\tAcc@1   3.91 (  3.91)\tAcc@5   6.25 (  6.25)\n",
            "Epoch: [2][ 50/391]\tTime  0.069 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.4681e+00 (4.4848e+00)\tAcc@1   5.47 (  2.21)\tAcc@5  11.72 ( 10.17)\n",
            "Epoch: [2][100/391]\tTime  0.077 ( 0.075)\tData  0.029 ( 0.028)\tLoss 4.3898e+00 (4.4859e+00)\tAcc@1   1.56 (  2.10)\tAcc@5  10.94 (  9.90)\n",
            "Epoch: [2][150/391]\tTime  0.077 ( 0.074)\tData  0.030 ( 0.028)\tLoss 4.4387e+00 (4.4791e+00)\tAcc@1   3.12 (  2.09)\tAcc@5  14.06 (  9.73)\n",
            "Epoch: [2][200/391]\tTime  0.066 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.5426e+00 (4.4736e+00)\tAcc@1   0.00 (  1.98)\tAcc@5   7.03 (  9.64)\n",
            "Epoch: [2][250/391]\tTime  0.073 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.4606e+00 (4.4726e+00)\tAcc@1   3.12 (  2.01)\tAcc@5  10.16 (  9.74)\n",
            "Epoch: [2][300/391]\tTime  0.066 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.4128e+00 (4.4674e+00)\tAcc@1   0.78 (  2.00)\tAcc@5   5.47 (  9.78)\n",
            "Epoch: [2][350/391]\tTime  0.074 ( 0.074)\tData  0.026 ( 0.028)\tLoss 4.3502e+00 (4.4632e+00)\tAcc@1   1.56 (  1.99)\tAcc@5  11.72 (  9.84)\n",
            "====> Acc@1 1.976 Acc@5 9.770\n",
            "====> Epoch loss 4.464\n",
            "====> 67.68 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.052 ( 0.052)\tLoss 4.5043e+00 (4.5043e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   5.47 (  5.47)\n",
            "Test: [50/79]\tTime  0.056 ( 0.055)\tLoss 4.5382e+00 (4.4622e+00)\tAcc@1   0.78 (  1.52)\tAcc@5   5.47 (  9.85)\n",
            "====> Acc@1 1.640 Acc@5 9.650\n",
            "====> 4.36 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 3, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [3][  0/391]\tTime  0.093 ( 0.093)\tData  0.042 ( 0.042)\tLoss 4.4812e+00 (4.4812e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   8.59 (  8.59)\n",
            "Epoch: [3][ 50/391]\tTime  0.074 ( 0.074)\tData  0.027 ( 0.028)\tLoss 4.4475e+00 (4.4361e+00)\tAcc@1   3.91 (  2.21)\tAcc@5  15.62 ( 10.97)\n",
            "Epoch: [3][100/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.4681e+00 (4.4456e+00)\tAcc@1   1.56 (  2.03)\tAcc@5  11.72 ( 10.33)\n",
            "Epoch: [3][150/391]\tTime  0.079 ( 0.074)\tData  0.032 ( 0.028)\tLoss 4.4595e+00 (4.4457e+00)\tAcc@1   4.69 (  2.18)\tAcc@5  10.16 ( 10.31)\n",
            "Epoch: [3][200/391]\tTime  0.068 ( 0.074)\tData  0.025 ( 0.028)\tLoss 4.4053e+00 (4.4444e+00)\tAcc@1   2.34 (  2.26)\tAcc@5   7.03 ( 10.24)\n",
            "Epoch: [3][250/391]\tTime  0.076 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.4445e+00 (4.4431e+00)\tAcc@1   1.56 (  2.18)\tAcc@5  11.72 ( 10.25)\n",
            "Epoch: [3][300/391]\tTime  0.067 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.4474e+00 (4.4422e+00)\tAcc@1   0.00 (  2.20)\tAcc@5  10.16 ( 10.22)\n",
            "Epoch: [3][350/391]\tTime  0.078 ( 0.074)\tData  0.030 ( 0.028)\tLoss 4.3644e+00 (4.4408e+00)\tAcc@1   0.78 (  2.21)\tAcc@5  10.94 ( 10.22)\n",
            "====> Acc@1 2.148 Acc@5 10.186\n",
            "====> Epoch loss 4.442\n",
            "====> 67.77 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.051 ( 0.051)\tLoss 4.4274e+00 (4.4274e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   9.38 (  9.38)\n",
            "Test: [50/79]\tTime  0.055 ( 0.054)\tLoss 4.4187e+00 (4.4257e+00)\tAcc@1   2.34 (  2.54)\tAcc@5  13.28 ( 10.95)\n",
            "====> Acc@1 2.360 Acc@5 10.520\n",
            "====> 4.23 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 4, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [4][  0/391]\tTime  0.068 ( 0.068)\tData  0.025 ( 0.025)\tLoss 4.3879e+00 (4.3879e+00)\tAcc@1   3.12 (  3.12)\tAcc@5   8.59 (  8.59)\n",
            "Epoch: [4][ 50/391]\tTime  0.066 ( 0.072)\tData  0.023 ( 0.026)\tLoss 4.4842e+00 (4.4238e+00)\tAcc@1   1.56 (  1.88)\tAcc@5   7.81 (  9.74)\n",
            "Epoch: [4][100/391]\tTime  0.074 ( 0.072)\tData  0.027 ( 0.027)\tLoss 4.4142e+00 (4.4317e+00)\tAcc@1   3.12 (  2.08)\tAcc@5  11.72 ( 10.05)\n",
            "Epoch: [4][150/391]\tTime  0.067 ( 0.072)\tData  0.024 ( 0.026)\tLoss 4.5305e+00 (4.4345e+00)\tAcc@1   0.00 (  2.11)\tAcc@5   5.47 ( 10.16)\n",
            "Epoch: [4][200/391]\tTime  0.074 ( 0.072)\tData  0.028 ( 0.027)\tLoss 4.3912e+00 (4.4332e+00)\tAcc@1   6.25 (  2.19)\tAcc@5  14.84 ( 10.30)\n",
            "Epoch: [4][250/391]\tTime  0.085 ( 0.072)\tData  0.037 ( 0.027)\tLoss 4.3340e+00 (4.4347e+00)\tAcc@1   3.12 (  2.15)\tAcc@5  17.19 ( 10.37)\n",
            "Epoch: [4][300/391]\tTime  0.072 ( 0.072)\tData  0.028 ( 0.027)\tLoss 4.5151e+00 (4.4364e+00)\tAcc@1   3.12 (  2.16)\tAcc@5   9.38 ( 10.25)\n",
            "Epoch: [4][350/391]\tTime  0.066 ( 0.072)\tData  0.022 ( 0.027)\tLoss 4.4556e+00 (4.4364e+00)\tAcc@1   1.56 (  2.14)\tAcc@5   9.38 ( 10.30)\n",
            "====> Acc@1 2.134 Acc@5 10.364\n",
            "====> Epoch loss 4.437\n",
            "====> 67.20 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.051 ( 0.051)\tLoss 4.4504e+00 (4.4504e+00)\tAcc@1   3.91 (  3.91)\tAcc@5  11.72 ( 11.72)\n",
            "Test: [50/79]\tTime  0.051 ( 0.054)\tLoss 4.5747e+00 (4.4472e+00)\tAcc@1   2.34 (  2.77)\tAcc@5   7.81 ( 11.76)\n",
            "====> Acc@1 2.620 Acc@5 11.390\n",
            "====> 4.19 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 5, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [5][  0/391]\tTime  0.078 ( 0.078)\tData  0.031 ( 0.031)\tLoss 4.6001e+00 (4.6001e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  13.28 ( 13.28)\n",
            "Epoch: [5][ 50/391]\tTime  0.066 ( 0.075)\tData  0.023 ( 0.028)\tLoss 4.5369e+00 (4.4325e+00)\tAcc@1   1.56 (  2.30)\tAcc@5   7.81 ( 11.01)\n",
            "Epoch: [5][100/391]\tTime  0.067 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.5280e+00 (4.4320e+00)\tAcc@1   0.78 (  2.31)\tAcc@5  10.16 ( 10.73)\n",
            "Epoch: [5][150/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.028)\tLoss 4.4156e+00 (4.4326e+00)\tAcc@1   1.56 (  2.23)\tAcc@5  10.94 ( 10.67)\n",
            "Epoch: [5][200/391]\tTime  0.073 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.3778e+00 (4.4324e+00)\tAcc@1   2.34 (  2.26)\tAcc@5  16.41 ( 10.68)\n",
            "Epoch: [5][250/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.3975e+00 (4.4307e+00)\tAcc@1   3.12 (  2.28)\tAcc@5  11.72 ( 10.58)\n",
            "Epoch: [5][300/391]\tTime  0.074 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.3914e+00 (4.4282e+00)\tAcc@1   2.34 (  2.33)\tAcc@5  14.06 ( 10.70)\n",
            "Epoch: [5][350/391]\tTime  0.069 ( 0.072)\tData  0.026 ( 0.027)\tLoss 4.4164e+00 (4.4262e+00)\tAcc@1   0.78 (  2.34)\tAcc@5   9.38 ( 10.77)\n",
            "====> Acc@1 2.332 Acc@5 10.756\n",
            "====> Epoch loss 4.429\n",
            "====> 67.38 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.057 ( 0.057)\tLoss 4.4368e+00 (4.4368e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  12.50 ( 12.50)\n",
            "Test: [50/79]\tTime  0.051 ( 0.055)\tLoss 4.4061e+00 (4.4209e+00)\tAcc@1   2.34 (  2.65)\tAcc@5   8.59 ( 11.61)\n",
            "====> Acc@1 2.480 Acc@5 11.450\n",
            "====> 4.28 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 6, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [6][  0/391]\tTime  0.079 ( 0.079)\tData  0.030 ( 0.030)\tLoss 4.4772e+00 (4.4772e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  11.72 ( 11.72)\n",
            "Epoch: [6][ 50/391]\tTime  0.074 ( 0.074)\tData  0.027 ( 0.028)\tLoss 4.4018e+00 (4.4173e+00)\tAcc@1   3.91 (  2.80)\tAcc@5  11.72 ( 11.29)\n",
            "Epoch: [6][100/391]\tTime  0.073 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.4318e+00 (4.4203e+00)\tAcc@1   2.34 (  2.73)\tAcc@5  11.72 ( 11.05)\n",
            "Epoch: [6][150/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.028)\tLoss 4.4341e+00 (4.4222e+00)\tAcc@1   1.56 (  2.60)\tAcc@5  10.16 ( 11.16)\n",
            "Epoch: [6][200/391]\tTime  0.081 ( 0.073)\tData  0.034 ( 0.027)\tLoss 4.3798e+00 (4.4230e+00)\tAcc@1   0.78 (  2.52)\tAcc@5  12.50 ( 10.98)\n",
            "Epoch: [6][250/391]\tTime  0.069 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.4639e+00 (4.4221e+00)\tAcc@1   1.56 (  2.46)\tAcc@5   7.03 ( 10.94)\n",
            "Epoch: [6][300/391]\tTime  0.070 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.4821e+00 (4.4219e+00)\tAcc@1   1.56 (  2.41)\tAcc@5   5.47 ( 10.97)\n",
            "Epoch: [6][350/391]\tTime  0.078 ( 0.073)\tData  0.031 ( 0.027)\tLoss 4.4957e+00 (4.4214e+00)\tAcc@1   0.78 (  2.42)\tAcc@5   5.47 ( 11.02)\n",
            "====> Acc@1 2.422 Acc@5 11.180\n",
            "====> Epoch loss 4.420\n",
            "====> 67.37 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.060 ( 0.060)\tLoss 4.4122e+00 (4.4122e+00)\tAcc@1   4.69 (  4.69)\tAcc@5  12.50 ( 12.50)\n",
            "Test: [50/79]\tTime  0.052 ( 0.054)\tLoss 4.3907e+00 (4.4119e+00)\tAcc@1   3.91 (  2.39)\tAcc@5  11.72 ( 11.41)\n",
            "====> Acc@1 2.510 Acc@5 11.300\n",
            "====> 4.19 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 7, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [7][  0/391]\tTime  0.078 ( 0.078)\tData  0.031 ( 0.031)\tLoss 4.3518e+00 (4.3518e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  14.06 ( 14.06)\n",
            "Epoch: [7][ 50/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.028)\tLoss 4.4374e+00 (4.3895e+00)\tAcc@1   1.56 (  2.36)\tAcc@5  10.16 ( 11.89)\n",
            "Epoch: [7][100/391]\tTime  0.066 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.3728e+00 (4.3973e+00)\tAcc@1   2.34 (  2.44)\tAcc@5  12.50 ( 12.05)\n",
            "Epoch: [7][150/391]\tTime  0.066 ( 0.072)\tData  0.022 ( 0.027)\tLoss 4.4303e+00 (4.3958e+00)\tAcc@1   0.78 (  2.55)\tAcc@5  11.72 ( 12.16)\n",
            "Epoch: [7][200/391]\tTime  0.065 ( 0.072)\tData  0.022 ( 0.027)\tLoss 4.4298e+00 (4.3919e+00)\tAcc@1   3.91 (  2.55)\tAcc@5   9.38 ( 12.25)\n",
            "Epoch: [7][250/391]\tTime  0.066 ( 0.072)\tData  0.024 ( 0.027)\tLoss 4.4142e+00 (4.3961e+00)\tAcc@1   1.56 (  2.50)\tAcc@5  13.28 ( 12.09)\n",
            "Epoch: [7][300/391]\tTime  0.066 ( 0.072)\tData  0.023 ( 0.027)\tLoss 4.4289e+00 (4.3971e+00)\tAcc@1   1.56 (  2.49)\tAcc@5  11.72 ( 12.04)\n",
            "Epoch: [7][350/391]\tTime  0.080 ( 0.072)\tData  0.033 ( 0.027)\tLoss 4.3395e+00 (4.3965e+00)\tAcc@1   2.34 (  2.51)\tAcc@5  14.84 ( 12.04)\n",
            "====> Acc@1 2.504 Acc@5 12.040\n",
            "====> Epoch loss 4.397\n",
            "====> 67.28 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.055 ( 0.055)\tLoss 4.4237e+00 (4.4237e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  13.28 ( 13.28)\n",
            "Test: [50/79]\tTime  0.051 ( 0.057)\tLoss 4.4026e+00 (4.4051e+00)\tAcc@1   3.12 (  3.02)\tAcc@5  12.50 ( 12.24)\n",
            "====> Acc@1 2.980 Acc@5 12.470\n",
            "====> 4.47 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 8, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [8][  0/391]\tTime  0.080 ( 0.080)\tData  0.030 ( 0.030)\tLoss 4.4128e+00 (4.4128e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  11.72 ( 11.72)\n",
            "Epoch: [8][ 50/391]\tTime  0.078 ( 0.074)\tData  0.032 ( 0.028)\tLoss 4.4622e+00 (4.3992e+00)\tAcc@1   1.56 (  2.48)\tAcc@5   7.81 ( 11.84)\n",
            "Epoch: [8][100/391]\tTime  0.072 ( 0.073)\tData  0.028 ( 0.028)\tLoss 4.2825e+00 (4.3939e+00)\tAcc@1   7.03 (  2.64)\tAcc@5  18.75 ( 12.33)\n",
            "Epoch: [8][150/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.4226e+00 (4.3881e+00)\tAcc@1   2.34 (  2.67)\tAcc@5  11.72 ( 12.30)\n",
            "Epoch: [8][200/391]\tTime  0.083 ( 0.073)\tData  0.039 ( 0.028)\tLoss 4.3506e+00 (4.3850e+00)\tAcc@1   1.56 (  2.71)\tAcc@5  16.41 ( 12.44)\n",
            "Epoch: [8][250/391]\tTime  0.089 ( 0.073)\tData  0.040 ( 0.027)\tLoss 4.3162e+00 (4.3816e+00)\tAcc@1   3.91 (  2.73)\tAcc@5  16.41 ( 12.61)\n",
            "Epoch: [8][300/391]\tTime  0.070 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.4449e+00 (4.3823e+00)\tAcc@1   3.91 (  2.70)\tAcc@5  12.50 ( 12.62)\n",
            "Epoch: [8][350/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.4069e+00 (4.3793e+00)\tAcc@1   1.56 (  2.72)\tAcc@5   7.81 ( 12.68)\n",
            "====> Acc@1 2.746 Acc@5 12.682\n",
            "====> Epoch loss 4.378\n",
            "====> 67.51 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.052 ( 0.052)\tLoss 4.4259e+00 (4.4259e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  13.28 ( 13.28)\n",
            "Test: [50/79]\tTime  0.061 ( 0.054)\tLoss 4.3850e+00 (4.3686e+00)\tAcc@1   1.56 (  2.79)\tAcc@5   8.59 ( 13.56)\n",
            "====> Acc@1 2.870 Acc@5 13.540\n",
            "====> 4.22 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 9, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [9][  0/391]\tTime  0.068 ( 0.068)\tData  0.026 ( 0.026)\tLoss 4.3581e+00 (4.3581e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  14.84 ( 14.84)\n",
            "Epoch: [9][ 50/391]\tTime  0.068 ( 0.071)\tData  0.025 ( 0.026)\tLoss 4.5325e+00 (4.3822e+00)\tAcc@1   3.12 (  2.76)\tAcc@5  16.41 ( 12.35)\n",
            "Epoch: [9][100/391]\tTime  0.078 ( 0.073)\tData  0.031 ( 0.028)\tLoss 4.3094e+00 (4.3657e+00)\tAcc@1   3.12 (  2.81)\tAcc@5  12.50 ( 12.85)\n",
            "Epoch: [9][150/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.2511e+00 (4.3722e+00)\tAcc@1   5.47 (  2.74)\tAcc@5  17.19 ( 12.50)\n",
            "Epoch: [9][200/391]\tTime  0.069 ( 0.074)\tData  0.025 ( 0.028)\tLoss 4.2618e+00 (4.3703e+00)\tAcc@1   3.91 (  2.72)\tAcc@5  17.19 ( 12.62)\n",
            "Epoch: [9][250/391]\tTime  0.078 ( 0.074)\tData  0.029 ( 0.028)\tLoss 4.3260e+00 (4.3713e+00)\tAcc@1   2.34 (  2.74)\tAcc@5  10.94 ( 12.64)\n",
            "Epoch: [9][300/391]\tTime  0.074 ( 0.075)\tData  0.027 ( 0.028)\tLoss 4.2917e+00 (4.3716e+00)\tAcc@1   3.12 (  2.74)\tAcc@5  10.16 ( 12.69)\n",
            "Epoch: [9][350/391]\tTime  0.076 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.3502e+00 (4.3702e+00)\tAcc@1   0.78 (  2.74)\tAcc@5  14.84 ( 12.66)\n",
            "====> Acc@1 2.764 Acc@5 12.758\n",
            "====> Epoch loss 4.369\n",
            "====> 67.93 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.059 ( 0.059)\tLoss 4.3799e+00 (4.3799e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  16.41 ( 16.41)\n",
            "Test: [50/79]\tTime  0.055 ( 0.056)\tLoss 4.4061e+00 (4.3551e+00)\tAcc@1   1.56 (  2.93)\tAcc@5  10.16 ( 13.53)\n",
            "====> Acc@1 2.910 Acc@5 13.450\n",
            "====> 4.36 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 10, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [10][  0/391]\tTime  0.078 ( 0.078)\tData  0.030 ( 0.030)\tLoss 4.3418e+00 (4.3418e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  10.16 ( 10.16)\n",
            "Epoch: [10][ 50/391]\tTime  0.075 ( 0.077)\tData  0.028 ( 0.030)\tLoss 4.3579e+00 (4.3512e+00)\tAcc@1   3.12 (  3.00)\tAcc@5  15.62 ( 13.10)\n",
            "Epoch: [10][100/391]\tTime  0.078 ( 0.077)\tData  0.030 ( 0.029)\tLoss 4.4175e+00 (4.3576e+00)\tAcc@1   2.34 (  2.92)\tAcc@5  10.94 ( 13.01)\n",
            "Epoch: [10][150/391]\tTime  0.079 ( 0.077)\tData  0.029 ( 0.030)\tLoss 4.3589e+00 (4.3610e+00)\tAcc@1   0.78 (  2.79)\tAcc@5  10.16 ( 12.74)\n",
            "Epoch: [10][200/391]\tTime  0.080 ( 0.077)\tData  0.032 ( 0.030)\tLoss 4.3972e+00 (4.3633e+00)\tAcc@1   3.12 (  2.86)\tAcc@5  13.28 ( 12.80)\n",
            "Epoch: [10][250/391]\tTime  0.068 ( 0.077)\tData  0.024 ( 0.030)\tLoss 4.3102e+00 (4.3638e+00)\tAcc@1   5.47 (  2.84)\tAcc@5  15.62 ( 12.71)\n",
            "Epoch: [10][300/391]\tTime  0.075 ( 0.076)\tData  0.028 ( 0.029)\tLoss 4.4279e+00 (4.3632e+00)\tAcc@1   3.91 (  2.84)\tAcc@5   8.59 ( 12.75)\n",
            "Epoch: [10][350/391]\tTime  0.076 ( 0.076)\tData  0.028 ( 0.029)\tLoss 4.4403e+00 (4.3625e+00)\tAcc@1   0.78 (  2.87)\tAcc@5  10.94 ( 12.88)\n",
            "====> Acc@1 2.882 Acc@5 12.952\n",
            "====> Epoch loss 4.360\n",
            "====> 68.51 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.056 ( 0.056)\tLoss 4.4178e+00 (4.4178e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  11.72 ( 11.72)\n",
            "Test: [50/79]\tTime  0.057 ( 0.057)\tLoss 4.4724e+00 (4.3749e+00)\tAcc@1   2.34 (  3.02)\tAcc@5  12.50 ( 13.30)\n",
            "====> Acc@1 3.130 Acc@5 13.080\n",
            "====> 4.38 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 11, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [11][  0/391]\tTime  0.077 ( 0.077)\tData  0.029 ( 0.029)\tLoss 4.2848e+00 (4.2848e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  12.50 ( 12.50)\n",
            "Epoch: [11][ 50/391]\tTime  0.076 ( 0.077)\tData  0.028 ( 0.029)\tLoss 4.3248e+00 (4.3528e+00)\tAcc@1   4.69 (  3.00)\tAcc@5  14.06 ( 13.28)\n",
            "Epoch: [11][100/391]\tTime  0.077 ( 0.076)\tData  0.029 ( 0.029)\tLoss 4.3463e+00 (4.3559e+00)\tAcc@1   1.56 (  2.82)\tAcc@5  14.84 ( 13.30)\n",
            "Epoch: [11][150/391]\tTime  0.079 ( 0.077)\tData  0.032 ( 0.029)\tLoss 4.4288e+00 (4.3562e+00)\tAcc@1   4.69 (  2.73)\tAcc@5  12.50 ( 13.38)\n",
            "Epoch: [11][200/391]\tTime  0.076 ( 0.076)\tData  0.029 ( 0.029)\tLoss 4.4342e+00 (4.3546e+00)\tAcc@1   2.34 (  2.79)\tAcc@5  10.94 ( 13.45)\n",
            "Epoch: [11][250/391]\tTime  0.074 ( 0.076)\tData  0.027 ( 0.029)\tLoss 4.3061e+00 (4.3523e+00)\tAcc@1   2.34 (  2.80)\tAcc@5  14.84 ( 13.42)\n",
            "Epoch: [11][300/391]\tTime  0.083 ( 0.076)\tData  0.032 ( 0.029)\tLoss 4.3922e+00 (4.3545e+00)\tAcc@1   1.56 (  2.80)\tAcc@5  14.84 ( 13.37)\n",
            "Epoch: [11][350/391]\tTime  0.078 ( 0.076)\tData  0.031 ( 0.029)\tLoss 4.3418e+00 (4.3544e+00)\tAcc@1   2.34 (  2.84)\tAcc@5  14.84 ( 13.39)\n",
            "====> Acc@1 2.854 Acc@5 13.444\n",
            "====> Epoch loss 4.353\n",
            "====> 68.41 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.057 ( 0.057)\tLoss 4.3611e+00 (4.3611e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  10.94 ( 10.94)\n",
            "Test: [50/79]\tTime  0.056 ( 0.055)\tLoss 4.4119e+00 (4.3516e+00)\tAcc@1   4.69 (  2.83)\tAcc@5   8.59 ( 13.88)\n",
            "====> Acc@1 2.850 Acc@5 13.790\n",
            "====> 4.29 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 12, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [12][  0/391]\tTime  0.077 ( 0.077)\tData  0.030 ( 0.030)\tLoss 4.4516e+00 (4.4516e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  13.28 ( 13.28)\n",
            "Epoch: [12][ 50/391]\tTime  0.074 ( 0.076)\tData  0.028 ( 0.029)\tLoss 4.3690e+00 (4.3399e+00)\tAcc@1   3.12 (  3.45)\tAcc@5  14.06 ( 14.57)\n",
            "Epoch: [12][100/391]\tTime  0.075 ( 0.075)\tData  0.028 ( 0.029)\tLoss 4.2330e+00 (4.3416e+00)\tAcc@1   3.91 (  3.36)\tAcc@5  14.84 ( 13.99)\n",
            "Epoch: [12][150/391]\tTime  0.075 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.1967e+00 (4.3417e+00)\tAcc@1   5.47 (  3.29)\tAcc@5  21.88 ( 14.01)\n",
            "Epoch: [12][200/391]\tTime  0.070 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.3150e+00 (4.3421e+00)\tAcc@1   2.34 (  3.17)\tAcc@5  13.28 ( 13.96)\n",
            "Epoch: [12][250/391]\tTime  0.077 ( 0.074)\tData  0.029 ( 0.028)\tLoss 4.3452e+00 (4.3443e+00)\tAcc@1   0.78 (  3.07)\tAcc@5  10.16 ( 13.67)\n",
            "Epoch: [12][300/391]\tTime  0.078 ( 0.074)\tData  0.031 ( 0.028)\tLoss 4.3484e+00 (4.3447e+00)\tAcc@1   0.78 (  3.12)\tAcc@5  14.84 ( 13.67)\n",
            "Epoch: [12][350/391]\tTime  0.080 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.3200e+00 (4.3439e+00)\tAcc@1   4.69 (  3.09)\tAcc@5  14.84 ( 13.68)\n",
            "====> Acc@1 3.052 Acc@5 13.574\n",
            "====> Epoch loss 4.346\n",
            "====> 67.92 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.056 ( 0.056)\tLoss 4.3882e+00 (4.3882e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  16.41 ( 16.41)\n",
            "Test: [50/79]\tTime  0.062 ( 0.055)\tLoss 4.4446e+00 (4.3643e+00)\tAcc@1   1.56 (  2.51)\tAcc@5  10.94 ( 12.93)\n",
            "====> Acc@1 2.640 Acc@5 13.110\n",
            "====> 4.43 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 13, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [13][  0/391]\tTime  0.076 ( 0.076)\tData  0.030 ( 0.030)\tLoss 4.4469e+00 (4.4469e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  11.72 ( 11.72)\n",
            "Epoch: [13][ 50/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.2933e+00 (4.3498e+00)\tAcc@1   2.34 (  2.93)\tAcc@5  14.06 ( 13.48)\n",
            "Epoch: [13][100/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.2125e+00 (4.3489e+00)\tAcc@1   3.91 (  2.85)\tAcc@5  17.97 ( 13.36)\n",
            "Epoch: [13][150/391]\tTime  0.078 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.2582e+00 (4.3434e+00)\tAcc@1   4.69 (  3.03)\tAcc@5  15.62 ( 13.91)\n",
            "Epoch: [13][200/391]\tTime  0.073 ( 0.073)\tData  0.026 ( 0.027)\tLoss 4.3755e+00 (4.3450e+00)\tAcc@1   4.69 (  2.92)\tAcc@5  14.06 ( 13.73)\n",
            "Epoch: [13][250/391]\tTime  0.072 ( 0.073)\tData  0.029 ( 0.027)\tLoss 4.2826e+00 (4.3444e+00)\tAcc@1   1.56 (  2.97)\tAcc@5  15.62 ( 13.83)\n",
            "Epoch: [13][300/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.4604e+00 (4.3441e+00)\tAcc@1   5.47 (  3.00)\tAcc@5  13.28 ( 13.79)\n",
            "Epoch: [13][350/391]\tTime  0.076 ( 0.074)\tData  0.029 ( 0.028)\tLoss 4.3009e+00 (4.3449e+00)\tAcc@1   2.34 (  2.99)\tAcc@5  11.72 ( 13.75)\n",
            "====> Acc@1 2.960 Acc@5 13.746\n",
            "====> Epoch loss 4.345\n",
            "====> 67.75 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.051 ( 0.051)\tLoss 4.3415e+00 (4.3415e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  15.62 ( 15.62)\n",
            "Test: [50/79]\tTime  0.059 ( 0.054)\tLoss 4.3216e+00 (4.3252e+00)\tAcc@1   3.91 (  2.97)\tAcc@5  15.62 ( 13.83)\n",
            "====> Acc@1 3.080 Acc@5 14.000\n",
            "====> 4.24 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 14, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [14][  0/391]\tTime  0.079 ( 0.079)\tData  0.032 ( 0.032)\tLoss 4.2950e+00 (4.2950e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  12.50 ( 12.50)\n",
            "Epoch: [14][ 50/391]\tTime  0.066 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.4445e+00 (4.3462e+00)\tAcc@1   3.12 (  3.03)\tAcc@5  14.84 ( 13.60)\n",
            "Epoch: [14][100/391]\tTime  0.070 ( 0.075)\tData  0.027 ( 0.029)\tLoss 4.3396e+00 (4.3342e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  10.94 ( 13.81)\n",
            "Epoch: [14][150/391]\tTime  0.078 ( 0.075)\tData  0.028 ( 0.028)\tLoss 4.2371e+00 (4.3358e+00)\tAcc@1   4.69 (  3.06)\tAcc@5  10.94 ( 13.88)\n",
            "Epoch: [14][200/391]\tTime  0.076 ( 0.075)\tData  0.028 ( 0.028)\tLoss 4.3717e+00 (4.3374e+00)\tAcc@1   2.34 (  3.02)\tAcc@5  14.06 ( 13.76)\n",
            "Epoch: [14][250/391]\tTime  0.080 ( 0.075)\tData  0.033 ( 0.029)\tLoss 4.3771e+00 (4.3372e+00)\tAcc@1   2.34 (  2.97)\tAcc@5  11.72 ( 13.76)\n",
            "Epoch: [14][300/391]\tTime  0.078 ( 0.075)\tData  0.030 ( 0.029)\tLoss 4.3786e+00 (4.3364e+00)\tAcc@1   1.56 (  3.02)\tAcc@5  18.75 ( 13.90)\n",
            "Epoch: [14][350/391]\tTime  0.077 ( 0.075)\tData  0.030 ( 0.029)\tLoss 4.2531e+00 (4.3385e+00)\tAcc@1   3.91 (  2.99)\tAcc@5  18.75 ( 13.85)\n",
            "====> Acc@1 2.976 Acc@5 13.866\n",
            "====> Epoch loss 4.339\n",
            "====> 68.15 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.056 ( 0.056)\tLoss 4.3551e+00 (4.3551e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  10.94 ( 10.94)\n",
            "Test: [50/79]\tTime  0.055 ( 0.056)\tLoss 4.3679e+00 (4.3314e+00)\tAcc@1   4.69 (  3.32)\tAcc@5   8.59 ( 13.88)\n",
            "====> Acc@1 3.350 Acc@5 14.170\n",
            "====> 4.47 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 15, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [15][  0/391]\tTime  0.093 ( 0.093)\tData  0.042 ( 0.042)\tLoss 4.3387e+00 (4.3387e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  13.28 ( 13.28)\n",
            "Epoch: [15][ 50/391]\tTime  0.075 ( 0.075)\tData  0.031 ( 0.029)\tLoss 4.4388e+00 (4.3444e+00)\tAcc@1   2.34 (  2.54)\tAcc@5  14.84 ( 13.43)\n",
            "Epoch: [15][100/391]\tTime  0.076 ( 0.075)\tData  0.033 ( 0.029)\tLoss 4.3060e+00 (4.3329e+00)\tAcc@1   5.47 (  2.88)\tAcc@5  13.28 ( 13.66)\n",
            "Epoch: [15][150/391]\tTime  0.073 ( 0.075)\tData  0.024 ( 0.028)\tLoss 4.3128e+00 (4.3334e+00)\tAcc@1   2.34 (  2.91)\tAcc@5  14.06 ( 13.97)\n",
            "Epoch: [15][200/391]\tTime  0.086 ( 0.076)\tData  0.035 ( 0.029)\tLoss 4.3400e+00 (4.3368e+00)\tAcc@1   2.34 (  2.92)\tAcc@5  14.84 ( 13.98)\n",
            "Epoch: [15][250/391]\tTime  0.074 ( 0.076)\tData  0.026 ( 0.029)\tLoss 4.3044e+00 (4.3370e+00)\tAcc@1   0.78 (  2.95)\tAcc@5  10.16 ( 14.02)\n",
            "Epoch: [15][300/391]\tTime  0.075 ( 0.075)\tData  0.028 ( 0.029)\tLoss 4.4295e+00 (4.3358e+00)\tAcc@1   1.56 (  3.03)\tAcc@5   9.38 ( 14.09)\n",
            "Epoch: [15][350/391]\tTime  0.067 ( 0.076)\tData  0.024 ( 0.029)\tLoss 4.2515e+00 (4.3366e+00)\tAcc@1   4.69 (  3.00)\tAcc@5  16.41 ( 14.09)\n",
            "====> Acc@1 2.968 Acc@5 14.032\n",
            "====> Epoch loss 4.337\n",
            "====> 68.28 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.056 ( 0.056)\tLoss 4.3173e+00 (4.3173e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  15.62 ( 15.62)\n",
            "Test: [50/79]\tTime  0.052 ( 0.056)\tLoss 4.3911e+00 (4.3204e+00)\tAcc@1   2.34 (  3.43)\tAcc@5  10.94 ( 14.71)\n",
            "====> Acc@1 3.370 Acc@5 14.210\n",
            "====> 4.37 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 16, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [16][  0/391]\tTime  0.082 ( 0.082)\tData  0.034 ( 0.034)\tLoss 4.3382e+00 (4.3382e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  12.50 ( 12.50)\n",
            "Epoch: [16][ 50/391]\tTime  0.071 ( 0.077)\tData  0.028 ( 0.030)\tLoss 4.3464e+00 (4.3458e+00)\tAcc@1   2.34 (  3.23)\tAcc@5   9.38 ( 13.82)\n",
            "Epoch: [16][100/391]\tTime  0.075 ( 0.076)\tData  0.028 ( 0.030)\tLoss 4.3905e+00 (4.3455e+00)\tAcc@1   3.12 (  3.06)\tAcc@5  14.84 ( 13.73)\n",
            "Epoch: [16][150/391]\tTime  0.074 ( 0.076)\tData  0.027 ( 0.030)\tLoss 4.2567e+00 (4.3383e+00)\tAcc@1   4.69 (  3.07)\tAcc@5  19.53 ( 13.90)\n",
            "Epoch: [16][200/391]\tTime  0.074 ( 0.076)\tData  0.027 ( 0.029)\tLoss 4.3192e+00 (4.3352e+00)\tAcc@1   4.69 (  3.06)\tAcc@5  13.28 ( 13.93)\n",
            "Epoch: [16][250/391]\tTime  0.074 ( 0.075)\tData  0.027 ( 0.029)\tLoss 4.3473e+00 (4.3376e+00)\tAcc@1   3.12 (  2.99)\tAcc@5  10.94 ( 13.91)\n",
            "Epoch: [16][300/391]\tTime  0.074 ( 0.075)\tData  0.028 ( 0.029)\tLoss 4.2966e+00 (4.3372e+00)\tAcc@1   5.47 (  3.03)\tAcc@5  21.09 ( 14.07)\n",
            "Epoch: [16][350/391]\tTime  0.071 ( 0.075)\tData  0.024 ( 0.029)\tLoss 4.2648e+00 (4.3358e+00)\tAcc@1   6.25 (  3.04)\tAcc@5  17.97 ( 14.11)\n",
            "====> Acc@1 3.092 Acc@5 14.094\n",
            "====> Epoch loss 4.335\n",
            "====> 68.05 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.057 ( 0.057)\tLoss 4.3329e+00 (4.3329e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  20.31 ( 20.31)\n",
            "Test: [50/79]\tTime  0.056 ( 0.055)\tLoss 4.3561e+00 (4.3412e+00)\tAcc@1   1.56 (  3.09)\tAcc@5  10.16 ( 15.07)\n",
            "====> Acc@1 3.210 Acc@5 14.860\n",
            "====> 4.29 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 17, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [17][  0/391]\tTime  0.069 ( 0.069)\tData  0.026 ( 0.026)\tLoss 4.3133e+00 (4.3133e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  12.50 ( 12.50)\n",
            "Epoch: [17][ 50/391]\tTime  0.066 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.2569e+00 (4.3302e+00)\tAcc@1   4.69 (  3.03)\tAcc@5  16.41 ( 14.69)\n",
            "Epoch: [17][100/391]\tTime  0.078 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.3178e+00 (4.3340e+00)\tAcc@1   2.34 (  3.00)\tAcc@5  13.28 ( 14.36)\n",
            "Epoch: [17][150/391]\tTime  0.077 ( 0.073)\tData  0.030 ( 0.027)\tLoss 4.3430e+00 (4.3322e+00)\tAcc@1   2.34 (  2.94)\tAcc@5  17.19 ( 14.25)\n",
            "Epoch: [17][200/391]\tTime  0.093 ( 0.073)\tData  0.042 ( 0.028)\tLoss 4.4122e+00 (4.3338e+00)\tAcc@1   0.78 (  2.94)\tAcc@5  10.16 ( 14.18)\n",
            "Epoch: [17][250/391]\tTime  0.067 ( 0.073)\tData  0.024 ( 0.028)\tLoss 4.2470e+00 (4.3331e+00)\tAcc@1   4.69 (  2.91)\tAcc@5  17.19 ( 14.09)\n",
            "Epoch: [17][300/391]\tTime  0.090 ( 0.073)\tData  0.041 ( 0.028)\tLoss 4.2890e+00 (4.3325e+00)\tAcc@1   3.12 (  2.90)\tAcc@5  13.28 ( 14.04)\n",
            "Epoch: [17][350/391]\tTime  0.078 ( 0.073)\tData  0.031 ( 0.027)\tLoss 4.3248e+00 (4.3315e+00)\tAcc@1   2.34 (  2.93)\tAcc@5  10.94 ( 14.11)\n",
            "====> Acc@1 2.916 Acc@5 14.048\n",
            "====> Epoch loss 4.333\n",
            "====> 67.65 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.052 ( 0.052)\tLoss 4.3483e+00 (4.3483e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  15.62 ( 15.62)\n",
            "Test: [50/79]\tTime  0.055 ( 0.056)\tLoss 4.4127e+00 (4.3489e+00)\tAcc@1   1.56 (  2.85)\tAcc@5  14.06 ( 13.89)\n",
            "====> Acc@1 3.060 Acc@5 13.730\n",
            "====> 4.34 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 18, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [18][  0/391]\tTime  0.068 ( 0.068)\tData  0.025 ( 0.025)\tLoss 4.4525e+00 (4.4525e+00)\tAcc@1   3.91 (  3.91)\tAcc@5  11.72 ( 11.72)\n",
            "Epoch: [18][ 50/391]\tTime  0.074 ( 0.074)\tData  0.029 ( 0.028)\tLoss 4.2218e+00 (4.3337e+00)\tAcc@1   1.56 (  2.91)\tAcc@5  10.16 ( 13.80)\n",
            "Epoch: [18][100/391]\tTime  0.076 ( 0.073)\tData  0.030 ( 0.027)\tLoss 4.3311e+00 (4.3364e+00)\tAcc@1   4.69 (  2.99)\tAcc@5  10.94 ( 13.93)\n",
            "Epoch: [18][150/391]\tTime  0.078 ( 0.073)\tData  0.028 ( 0.028)\tLoss 4.3943e+00 (4.3342e+00)\tAcc@1   5.47 (  3.02)\tAcc@5  16.41 ( 14.32)\n",
            "Epoch: [18][200/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.028)\tLoss 4.3311e+00 (4.3337e+00)\tAcc@1   2.34 (  3.04)\tAcc@5  17.97 ( 14.33)\n",
            "Epoch: [18][250/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.2694e+00 (4.3340e+00)\tAcc@1   5.47 (  3.06)\tAcc@5  19.53 ( 14.15)\n",
            "Epoch: [18][300/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.4252e+00 (4.3347e+00)\tAcc@1   3.12 (  3.14)\tAcc@5  14.06 ( 14.28)\n",
            "Epoch: [18][350/391]\tTime  0.066 ( 0.073)\tData  0.023 ( 0.028)\tLoss 4.3365e+00 (4.3349e+00)\tAcc@1   0.78 (  3.10)\tAcc@5  17.97 ( 14.21)\n",
            "====> Acc@1 3.092 Acc@5 14.250\n",
            "====> Epoch loss 4.334\n",
            "====> 67.58 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.062 ( 0.062)\tLoss 4.3471e+00 (4.3471e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  13.28 ( 13.28)\n",
            "Test: [50/79]\tTime  0.051 ( 0.055)\tLoss 4.3277e+00 (4.3143e+00)\tAcc@1   1.56 (  3.16)\tAcc@5  10.94 ( 14.09)\n",
            "====> Acc@1 3.230 Acc@5 14.250\n",
            "====> 4.27 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 19, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [19][  0/391]\tTime  0.068 ( 0.068)\tData  0.026 ( 0.026)\tLoss 4.3093e+00 (4.3093e+00)\tAcc@1   7.03 (  7.03)\tAcc@5  22.66 ( 22.66)\n",
            "Epoch: [19][ 50/391]\tTime  0.071 ( 0.072)\tData  0.023 ( 0.026)\tLoss 4.2151e+00 (4.3217e+00)\tAcc@1   6.25 (  3.11)\tAcc@5  21.88 ( 14.20)\n",
            "Epoch: [19][100/391]\tTime  0.085 ( 0.073)\tData  0.036 ( 0.028)\tLoss 4.4350e+00 (4.3242e+00)\tAcc@1   3.91 (  3.09)\tAcc@5  17.19 ( 14.48)\n",
            "Epoch: [19][150/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.4164e+00 (4.3283e+00)\tAcc@1   1.56 (  3.12)\tAcc@5  10.16 ( 14.17)\n",
            "Epoch: [19][200/391]\tTime  0.073 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.3944e+00 (4.3276e+00)\tAcc@1   1.56 (  3.13)\tAcc@5  14.84 ( 14.25)\n",
            "Epoch: [19][250/391]\tTime  0.086 ( 0.073)\tData  0.039 ( 0.028)\tLoss 4.3736e+00 (4.3283e+00)\tAcc@1   1.56 (  3.09)\tAcc@5  12.50 ( 14.20)\n",
            "Epoch: [19][300/391]\tTime  0.071 ( 0.073)\tData  0.024 ( 0.028)\tLoss 4.3440e+00 (4.3297e+00)\tAcc@1   1.56 (  3.10)\tAcc@5  14.06 ( 14.17)\n",
            "Epoch: [19][350/391]\tTime  0.076 ( 0.073)\tData  0.029 ( 0.027)\tLoss 4.3139e+00 (4.3301e+00)\tAcc@1   3.91 (  3.03)\tAcc@5  10.94 ( 14.08)\n",
            "====> Acc@1 3.040 Acc@5 14.060\n",
            "====> Epoch loss 4.331\n",
            "====> 67.55 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.052 ( 0.052)\tLoss 4.3318e+00 (4.3318e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  17.19 ( 17.19)\n",
            "Test: [50/79]\tTime  0.057 ( 0.054)\tLoss 4.3865e+00 (4.3206e+00)\tAcc@1   3.91 (  3.37)\tAcc@5  16.41 ( 15.24)\n",
            "====> Acc@1 3.390 Acc@5 14.760\n",
            "====> 4.36 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 20, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [20][  0/391]\tTime  0.082 ( 0.082)\tData  0.033 ( 0.033)\tLoss 4.3186e+00 (4.3186e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  15.62 ( 15.62)\n",
            "Epoch: [20][ 50/391]\tTime  0.065 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.2428e+00 (4.3255e+00)\tAcc@1   5.47 (  3.05)\tAcc@5  14.84 ( 14.55)\n",
            "Epoch: [20][100/391]\tTime  0.076 ( 0.073)\tData  0.029 ( 0.027)\tLoss 4.3679e+00 (4.3283e+00)\tAcc@1   6.25 (  3.19)\tAcc@5  15.62 ( 14.23)\n",
            "Epoch: [20][150/391]\tTime  0.068 ( 0.074)\tData  0.025 ( 0.028)\tLoss 4.3048e+00 (4.3296e+00)\tAcc@1   0.78 (  3.09)\tAcc@5  14.84 ( 14.26)\n",
            "Epoch: [20][200/391]\tTime  0.074 ( 0.074)\tData  0.027 ( 0.028)\tLoss 4.1828e+00 (4.3276e+00)\tAcc@1   3.12 (  3.09)\tAcc@5  17.19 ( 14.35)\n",
            "Epoch: [20][250/391]\tTime  0.067 ( 0.074)\tData  0.024 ( 0.028)\tLoss 4.3342e+00 (4.3287e+00)\tAcc@1   3.91 (  3.08)\tAcc@5  15.62 ( 14.32)\n",
            "Epoch: [20][300/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.2773e+00 (4.3297e+00)\tAcc@1   3.91 (  3.12)\tAcc@5  15.62 ( 14.27)\n",
            "Epoch: [20][350/391]\tTime  0.075 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.3886e+00 (4.3285e+00)\tAcc@1   2.34 (  3.17)\tAcc@5  17.19 ( 14.31)\n",
            "====> Acc@1 3.148 Acc@5 14.230\n",
            "====> Epoch loss 4.330\n",
            "====> 67.57 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.054 ( 0.054)\tLoss 4.3206e+00 (4.3206e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  10.16 ( 10.16)\n",
            "Test: [50/79]\tTime  0.051 ( 0.053)\tLoss 4.3526e+00 (4.3143e+00)\tAcc@1   3.91 (  3.23)\tAcc@5  10.94 ( 14.35)\n",
            "====> Acc@1 3.080 Acc@5 14.500\n",
            "====> 4.18 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 21, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [21][  0/391]\tTime  0.076 ( 0.076)\tData  0.029 ( 0.029)\tLoss 4.3909e+00 (4.3909e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  10.94 ( 10.94)\n",
            "Epoch: [21][ 50/391]\tTime  0.066 ( 0.073)\tData  0.023 ( 0.028)\tLoss 4.3281e+00 (4.3255e+00)\tAcc@1   3.12 (  3.28)\tAcc@5  12.50 ( 13.94)\n",
            "Epoch: [21][100/391]\tTime  0.065 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.1866e+00 (4.3294e+00)\tAcc@1   3.91 (  3.15)\tAcc@5  17.97 ( 13.83)\n",
            "Epoch: [21][150/391]\tTime  0.066 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.3708e+00 (4.3333e+00)\tAcc@1   3.91 (  3.07)\tAcc@5  12.50 ( 13.98)\n",
            "Epoch: [21][200/391]\tTime  0.074 ( 0.073)\tData  0.032 ( 0.028)\tLoss 4.3894e+00 (4.3330e+00)\tAcc@1   1.56 (  3.09)\tAcc@5  12.50 ( 14.06)\n",
            "Epoch: [21][250/391]\tTime  0.089 ( 0.073)\tData  0.039 ( 0.028)\tLoss 4.3068e+00 (4.3288e+00)\tAcc@1   3.12 (  3.14)\tAcc@5  11.72 ( 14.18)\n",
            "Epoch: [21][300/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.4309e+00 (4.3261e+00)\tAcc@1   2.34 (  3.16)\tAcc@5  13.28 ( 14.12)\n",
            "Epoch: [21][350/391]\tTime  0.070 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.3921e+00 (4.3276e+00)\tAcc@1   2.34 (  3.15)\tAcc@5  12.50 ( 14.13)\n",
            "====> Acc@1 3.122 Acc@5 14.098\n",
            "====> Epoch loss 4.327\n",
            "====> 67.50 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.055 ( 0.055)\tLoss 4.3153e+00 (4.3153e+00)\tAcc@1   1.56 (  1.56)\tAcc@5  17.97 ( 17.97)\n",
            "Test: [50/79]\tTime  0.051 ( 0.054)\tLoss 4.3935e+00 (4.3186e+00)\tAcc@1   1.56 (  3.23)\tAcc@5  10.16 ( 14.32)\n",
            "====> Acc@1 3.330 Acc@5 14.450\n",
            "====> 4.23 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 22, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [22][  0/391]\tTime  0.076 ( 0.076)\tData  0.029 ( 0.029)\tLoss 4.3351e+00 (4.3351e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  14.06 ( 14.06)\n",
            "Epoch: [22][ 50/391]\tTime  0.071 ( 0.076)\tData  0.028 ( 0.030)\tLoss 4.2544e+00 (4.3291e+00)\tAcc@1   5.47 (  3.45)\tAcc@5  14.84 ( 14.63)\n",
            "Epoch: [22][100/391]\tTime  0.065 ( 0.073)\tData  0.022 ( 0.028)\tLoss 4.3248e+00 (4.3319e+00)\tAcc@1   2.34 (  3.25)\tAcc@5  10.16 ( 14.56)\n",
            "Epoch: [22][150/391]\tTime  0.068 ( 0.073)\tData  0.025 ( 0.028)\tLoss 4.3931e+00 (4.3318e+00)\tAcc@1   4.69 (  3.14)\tAcc@5  14.84 ( 14.36)\n",
            "Epoch: [22][200/391]\tTime  0.075 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.3991e+00 (4.3299e+00)\tAcc@1   4.69 (  3.12)\tAcc@5  17.19 ( 14.30)\n",
            "Epoch: [22][250/391]\tTime  0.076 ( 0.074)\tData  0.028 ( 0.028)\tLoss 4.3625e+00 (4.3323e+00)\tAcc@1   3.12 (  3.05)\tAcc@5  11.72 ( 14.24)\n",
            "Epoch: [22][300/391]\tTime  0.074 ( 0.073)\tData  0.027 ( 0.028)\tLoss 4.2102e+00 (4.3315e+00)\tAcc@1   4.69 (  3.03)\tAcc@5  19.53 ( 14.25)\n",
            "Epoch: [22][350/391]\tTime  0.072 ( 0.073)\tData  0.026 ( 0.027)\tLoss 4.2575e+00 (4.3306e+00)\tAcc@1   6.25 (  3.08)\tAcc@5  14.06 ( 14.19)\n",
            "====> Acc@1 3.072 Acc@5 14.208\n",
            "====> Epoch loss 4.330\n",
            "====> 67.61 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.051 ( 0.051)\tLoss 4.3178e+00 (4.3178e+00)\tAcc@1   4.69 (  4.69)\tAcc@5  19.53 ( 19.53)\n",
            "Test: [50/79]\tTime  0.051 ( 0.053)\tLoss 4.3723e+00 (4.3128e+00)\tAcc@1   1.56 (  3.35)\tAcc@5  10.94 ( 15.10)\n",
            "====> Acc@1 3.390 Acc@5 15.250\n",
            "====> 4.19 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 23, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [23][  0/391]\tTime  0.074 ( 0.074)\tData  0.025 ( 0.025)\tLoss 4.2735e+00 (4.2735e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  14.84 ( 14.84)\n",
            "Epoch: [23][ 50/391]\tTime  0.073 ( 0.074)\tData  0.027 ( 0.028)\tLoss 4.2633e+00 (4.3122e+00)\tAcc@1   1.56 (  3.05)\tAcc@5  16.41 ( 14.63)\n",
            "Epoch: [23][100/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.2288e+00 (4.3275e+00)\tAcc@1   3.91 (  2.99)\tAcc@5   9.38 ( 14.26)\n",
            "Epoch: [23][150/391]\tTime  0.078 ( 0.073)\tData  0.027 ( 0.027)\tLoss 4.2647e+00 (4.3293e+00)\tAcc@1   5.47 (  3.11)\tAcc@5  15.62 ( 14.09)\n",
            "Epoch: [23][200/391]\tTime  0.075 ( 0.073)\tData  0.028 ( 0.027)\tLoss 4.3492e+00 (4.3249e+00)\tAcc@1   5.47 (  3.20)\tAcc@5  14.06 ( 14.33)\n",
            "Epoch: [23][250/391]\tTime  0.065 ( 0.073)\tData  0.023 ( 0.027)\tLoss 4.3053e+00 (4.3250e+00)\tAcc@1   3.12 (  3.14)\tAcc@5  11.72 ( 14.28)\n",
            "Epoch: [23][300/391]\tTime  0.065 ( 0.074)\tData  0.023 ( 0.028)\tLoss 4.3083e+00 (4.3279e+00)\tAcc@1   4.69 (  3.14)\tAcc@5  19.53 ( 14.10)\n",
            "Epoch: [23][350/391]\tTime  0.082 ( 0.074)\tData  0.032 ( 0.028)\tLoss 4.1863e+00 (4.3248e+00)\tAcc@1   5.47 (  3.16)\tAcc@5  20.31 ( 14.10)\n",
            "====> Acc@1 3.160 Acc@5 14.144\n",
            "====> Epoch loss 4.324\n",
            "====> 67.80 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/79]\tTime  0.056 ( 0.056)\tLoss 4.2933e+00 (4.2933e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  15.62 ( 15.62)\n",
            "Test: [50/79]\tTime  0.055 ( 0.055)\tLoss 4.3424e+00 (4.3114e+00)\tAcc@1   3.12 (  2.74)\tAcc@5  10.94 ( 15.12)\n",
            "====> Acc@1 3.060 Acc@5 15.160\n",
            "====> 4.35 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 24, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [24][  0/391]\tTime  0.078 ( 0.078)\tData  0.030 ( 0.030)\tLoss 4.2746e+00 (4.2746e+00)\tAcc@1   2.34 (  2.34)\tAcc@5  15.62 ( 15.62)\n",
            "Epoch: [24][ 50/391]\tTime  0.075 ( 0.076)\tData  0.028 ( 0.029)\tLoss 4.3649e+00 (4.3366e+00)\tAcc@1   2.34 (  3.00)\tAcc@5  14.06 ( 14.41)\n",
            "Epoch: [24][100/391]\tTime  0.077 ( 0.075)\tData  0.028 ( 0.029)\tLoss 4.2888e+00 (4.3229e+00)\tAcc@1   3.12 (  3.11)\tAcc@5  11.72 ( 14.57)\n",
            "Epoch: [24][150/391]\tTime  0.074 ( 0.075)\tData  0.031 ( 0.029)\tLoss 4.3491e+00 (4.3219e+00)\tAcc@1   4.69 (  3.08)\tAcc@5  16.41 ( 14.48)\n",
            "Epoch: [24][200/391]\tTime  0.069 ( 0.075)\tData  0.026 ( 0.029)\tLoss 4.3232e+00 (4.3266e+00)\tAcc@1   0.78 (  2.93)\tAcc@5  14.06 ( 14.11)\n",
            "Epoch: [24][250/391]\tTime  0.067 ( 0.075)\tData  0.024 ( 0.029)\tLoss 4.2681e+00 (4.3250e+00)\tAcc@1   3.12 (  2.97)\tAcc@5  18.75 ( 14.27)\n",
            "Epoch: [24][300/391]\tTime  0.077 ( 0.075)\tData  0.029 ( 0.029)\tLoss 4.3087e+00 (4.3243e+00)\tAcc@1   4.69 (  3.04)\tAcc@5  17.97 ( 14.33)\n",
            "Epoch: [24][350/391]\tTime  0.073 ( 0.075)\tData  0.026 ( 0.029)\tLoss 4.3247e+00 (4.3255e+00)\tAcc@1   1.56 (  3.03)\tAcc@5  12.50 ( 14.33)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}