{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobilenetv1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHMv_34RP2nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a1942b-dae9-4b43-89be-d9458cca9816"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBiayO0oitI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DepthwiseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=1):\n",
        "        super(DepthwiseConv2d, self).__init__()\n",
        "\n",
        "        self.depthwiseconv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.depthwiseconv(x)\n",
        "\n",
        "class PointwiseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0):\n",
        "        super(PointwiseConv2d, self).__init__()\n",
        "\n",
        "        self.pointwiseconv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pointwiseconv(x)\n",
        "\n",
        "\n",
        "class MobileNetv1(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(MobileNetv1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            DepthwiseConv2d(32, 32, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(32, 64, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(64, 64, kernel_size=3, stride=2),\n",
        "            PointwiseConv2d(64, 128, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(128, 128, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(128, 128, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(128, 128, kernel_size=3, stride=2),\n",
        "            PointwiseConv2d(128, 256, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(256, 256, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(256, 256, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(256, 256, kernel_size=3, stride=2),\n",
        "            PointwiseConv2d(256, 512, kernel_size=1, stride=1),\n",
        "\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(512, 512, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(512, 512, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(512, 512, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(512, 512, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=1),\n",
        "            PointwiseConv2d(512, 512, kernel_size=1, stride=1),\n",
        "\n",
        "            DepthwiseConv2d(512, 512, kernel_size=3, stride=2),\n",
        "            PointwiseConv2d(512, 1024, kernel_size=1, stride=1),\n",
        "            DepthwiseConv2d(1024, 1024, kernel_size=3, stride=2),\n",
        "            PointwiseConv2d(1024, 1024, kernel_size=1, stride=1),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def mobilenetv1():\n",
        "    return MobileNetv1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDTTk-VsjAPS",
        "colab_type": "text"
      },
      "source": [
        "config.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxauZ6_XimSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import easydict\n",
        "\n",
        "\n",
        "def config():\n",
        "  \n",
        "    cfg = easydict.EasyDict({\n",
        "            \"arch\": \"mobilenetv1_20200415\",\n",
        "            \"dataset\": \"cifar100\",\n",
        "            \"batch_size\": 256,\n",
        "            \"epochs\": 200,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"weight_decay\": 0,\n",
        "            \"momentum\": 0.9,\n",
        "            \"nesterov\": True,\n",
        "            \"print_freq\": 50,\n",
        "            \"ckpt\": \"/content/drive/My Drive/MLVC/Baseline/checkpoint/mobilnetv1_20200415/\",\n",
        "            \"results_dir\": \"./results/\",\n",
        "            \"resume\": False,\n",
        "            \"evaluate\": False,\n",
        "            \"cuda\": True,\n",
        "            \"gpuids\": [0],\n",
        "            \"colab\": True,    \n",
        "    })\n",
        "\n",
        "\n",
        "    cfg.gpuids = list(map(int, cfg.gpuids))\n",
        "\n",
        "    model = mobilenetv1()\n",
        "    if cfg.arch == \"mobilenetv1_20200415\":\n",
        "        model = mobilenetv1()\n",
        "    #elif cfg.arch == \"resnet-cifar\":\n",
        "    #    model = resnet.resnet20()\n",
        "    #elif cfg.arch == \"vgg-cifar-binary\":\n",
        "    #    model = vgg_bnn.vgg11()\n",
        "    #elif cfg.arch == \"resnet-cifar-dorefa\":\n",
        "    #    model = resnet_dorefanet.resnet20()\n",
        "\n",
        "    return cfg, model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uijg3T_jKpH",
        "colab_type": "text"
      },
      "source": [
        "utility.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAxpnTajMvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def load_model(model, ckpt_file, args):\n",
        "    if args.cuda:\n",
        "        checkpoint = torch.load(\n",
        "            ckpt_file, map_location=lambda storage, loc: storage.cuda(args.gpuids[0])\n",
        "        )\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            model.module.load_state_dict(checkpoint[\"model\"])\n",
        "    else:\n",
        "        checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
        "        try:\n",
        "            model.load_state_dict(checkpoint[\"model\"])\n",
        "        except:  # noqa\n",
        "            # create new OrderedDict that does not contain `module.`\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in checkpoint[\"model\"].items():\n",
        "                if k[:7] == \"module.\":\n",
        "                    name = k[7:]  # remove `module.`\n",
        "                else:\n",
        "                    name = k[:]\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "            model.load_state_dict(new_state_dict)\n",
        "\n",
        "    return checkpoint\n",
        "\n",
        "\n",
        "def save_model(state, epoch, is_best, args):\n",
        "    dir_ckpt = pathlib.Path(\"/content/drive/My Drive/MLVC/Baseline/checkpoint/mobilnetv1_20200415/\")\n",
        "    dir_path = dir_ckpt / args.dataset\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model_file = dir_path / \"ckpt_epoch_{}.pth\".format(epoch)\n",
        "    torch.save(state, model_file)\n",
        "\n",
        "    if is_best:\n",
        "        shutil.copyfile(model_file, dir_path / \"ckpt_best.pth\")\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=\":f\"):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print(\"\\t\".join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
        "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr):\n",
        "    \"\"\"Sets the learning rate, decayed rate of 0.1 every epoch\"\"\"\n",
        "    #if epoch >= 60:\n",
        "    #    lr = 0.01\n",
        "    #if epoch >= 120:\n",
        "    #    lr = 0.001\n",
        "    #if epoch >= 160:\n",
        "    #    lr = 0.0001\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "    return lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def print_reults(start_time, train_time, validate_time, start_epoch, epochs):\n",
        "    avg_train_time = train_time / (epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600), int((elapsed_time % 3600) // 60), elapsed_time % 60\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NYZJ-dXjZLX",
        "colab_type": "text"
      },
      "source": [
        "data_loader.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHxY6xojjcH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "def dataloader(dataset, batch_size):\n",
        "    train_dataset, val_dataset = load_cifar10()\n",
        "\n",
        "    if dataset == \"cifar100\":\n",
        "        train_dataset, val_dataset = load_cifar100()\n",
        "\n",
        "    # Data loader\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def load_cifar10():\n",
        "    # CIFAR-10 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR10(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def load_cifar100():\n",
        "    # CIFAR-100 dataset\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n",
        "    )\n",
        "    train_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.Pad(4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "        ),\n",
        "        download=True,\n",
        "    )\n",
        "\n",
        "    val_dataset = datasets.CIFAR100(\n",
        "        root=\"../../data/\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
        "    )\n",
        "    return train_dataset, val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY8Jl99qjgEL",
        "colab_type": "text"
      },
      "source": [
        "main.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4lPApbXhvVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fead4a20-bcfe-4735-e46c-f72889a1a5df"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import time\n",
        "import pathlib\n",
        "from os.path import isfile\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args, start_epoch, best_acc1\n",
        "    args, model = config()\n",
        "\n",
        "    print(\"Model: {}\".format(args.arch))\n",
        "\n",
        "    if args.cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        momentum=args.momentum,\n",
        "        nesterov=args.nesterov,\n",
        "    )\n",
        "\n",
        "    best_acc1 = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if args.cuda:\n",
        "        torch.cuda.set_device(args.gpuids[0])\n",
        "        with torch.cuda.device(args.gpuids[0]):\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "        model = nn.DataParallel(\n",
        "            model, device_ids=args.gpuids, output_device=args.gpuids[0]\n",
        "        )\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    # checkpoint file\n",
        "    ckpt_dir = pathlib.Path(args.ckpt)\n",
        "    ckpt_file = ckpt_dir / args.dataset / args.ckpt\n",
        "\n",
        "    # for resuming training\n",
        "    if args.resume:\n",
        "        retrain(ckpt_file, model, optimizer)\n",
        "\n",
        "    # Data loading\n",
        "    print(\"\\n==> Load data..\")\n",
        "    train_loader, val_loader = dataloader(args.dataset, args.batch_size)\n",
        "\n",
        "    # initiailizae\n",
        "    train_time, validate_time = 0.0, 0.0\n",
        "    avgloss_train = 0.0\n",
        "    acc1_train, acc5_train, acc1_valid, acc5_valid = 0.0, 0.0, 0.0, 0.0\n",
        "    is_best = False\n",
        "\n",
        "    # result lists\n",
        "    result_epoch, result_lr, result_train_avgtime, result_train_avgloss = [], [], [], []\n",
        "    result_train_avgtop1acc, result_train_avgtop5acc = [], []\n",
        "    result_val_avgtime, result_val_avgtop1acc, result_val_avgtop5acc = [], [], []\n",
        "\n",
        "    # train...\n",
        "    lr = args.learning_rate\n",
        "    curr_lr = lr\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        curr_lr = adjust_learning_rate(optimizer, epoch, lr)\n",
        "        print(\"\\n==> Epoch: {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "        # train for one epoch\n",
        "        train_time, acc1_train, acc5_train, avgloss_train = train_epoch(\n",
        "            train_time,\n",
        "            acc1_train,\n",
        "            acc5_train,\n",
        "            avgloss_train,\n",
        "            train_loader,\n",
        "            epoch,\n",
        "            model,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "        )\n",
        "\n",
        "        # evaluate on validation set\n",
        "        validate_time, acc1_valid, acc5_valid = validation_epoch(\n",
        "            validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "        )\n",
        "\n",
        "        # remember best Acc@1 and save checkpoint\n",
        "        is_best = save_model_data(\n",
        "            is_best, best_acc1, acc1_valid, epoch, model, optimizer, args\n",
        "        )\n",
        "\n",
        "\n",
        "        result_epoch.append(epoch)\n",
        "        result_lr.append(curr_lr)\n",
        "        result_train_avgtime.append(train_time)\n",
        "        result_train_avgloss.append(avgloss_train)\n",
        "        result_train_avgtop1acc.append(acc1_train.item())\n",
        "        result_train_avgtop5acc.append(acc5_train.item())\n",
        "        result_val_avgtop1acc.append(acc1_valid.item())\n",
        "        result_val_avgtop5acc.append(acc5_valid.item())\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Epoch': result_epoch,\n",
        "            'Learning rate': result_lr,\n",
        "            'Training avg loss': result_train_avgloss,\n",
        "            'Training avg top1 acc': result_train_avgtop1acc,\n",
        "            'Training avg top5 acc': result_train_avgtop5acc,\n",
        "            'Test avg top1 acc': result_val_avgtop1acc,\n",
        "            'Test avg top5 acc': result_val_avgtop5acc,\n",
        "        })\n",
        "\n",
        "        if args.colab:\n",
        "            df.to_csv('/content/drive/My Drive/MLVC/Baseline/results/{}_result.csv'.format(args.arch))\n",
        "        else:\n",
        "            df.to_csv('./results/{}_result.csv'.format(args.arch))\n",
        "\n",
        "\n",
        "    print_results(train_time, validate_time)\n",
        "\n",
        "\n",
        "def retrain(ckpt_file, model, optimizer):\n",
        "    if isfile(ckpt_file):\n",
        "        print(\"\\n==> Loading Checkpoint '{}'\".format(args.ckpt))\n",
        "        checkpoint = load_model(model, ckpt_file, args)\n",
        "\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "        print(\"==> Loaded Checkpoint '{}' (epoch {})\".format(args.ckpt, start_epoch))\n",
        "    else:\n",
        "        print(\"==> no checkpoint found '{}'\".format(args.ckpt))\n",
        "        return\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    train_time, acc1_train, acc5_train, avgloss_train, train_loader, epoch, model, criterion, optimizer\n",
        "):\n",
        "    print(\"===> [ Training ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_train, acc5_train, avgloss_train = train(\n",
        "        train_loader, epoch=epoch, model=model, criterion=criterion, optimizer=optimizer\n",
        "    )\n",
        "    elapsed_time = time.time() - start_time\n",
        "    train_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to train this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return train_time, acc1_train, acc5_train, avgloss_train\n",
        "\n",
        "\n",
        "def validation_epoch(\n",
        "    validate_time, acc1_valid, acc5_valid, val_loader, model, criterion\n",
        "):\n",
        "    print(\"===> [ Validation ]\")\n",
        "    start_time = time.time()\n",
        "    acc1_valid, acc5_valid, avgloss_valid = validate(val_loader, model, criterion)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    validate_time += elapsed_time\n",
        "    print(\"====> {:.2f} seconds to validate this epoch\\n\".format(elapsed_time))\n",
        "\n",
        "    return validate_time, acc1_valid, acc5_valid\n",
        "\n",
        "\n",
        "def save_model_data(is_best, best_acc1, acc1_valid, epoch, model, optimizer, args):\n",
        "    is_best = acc1_valid > best_acc1\n",
        "    best_acc1 = max(acc1_valid, best_acc1)\n",
        "    state = {\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        save_model(state, epoch, is_best, args)\n",
        "    return is_best\n",
        "\n",
        "\n",
        "def train(train_loader, **kwargs):\n",
        "    epoch = kwargs.get(\"epoch\")\n",
        "    model = kwargs.get(\"model\")\n",
        "    criterion = kwargs.get(\"criterion\")\n",
        "    optimizer = kwargs.get(\"optimizer\")\n",
        "\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        batch_time,\n",
        "        data_time,\n",
        "        losses,\n",
        "        top1,\n",
        "        top5,\n",
        "        prefix=\"Epoch: [{}]\".format(epoch),\n",
        "    )\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    running_loss = 0.0\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.cuda:\n",
        "            input = input.cuda(non_blocking=True)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0], input.size(0))\n",
        "        top5.update(acc5[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "    print(\n",
        "        \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(top1=top1, top5=top5)\n",
        "    )\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(\"====> Epoch loss {:.3f}\".format(epoch_loss))\n",
        "\n",
        "    return top1.avg, top5.avg, epoch_loss\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
        "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
        "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
        "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader), batch_time, losses, top1, top5, prefix=\"Test: \"\n",
        "    )\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            if args.cuda:\n",
        "                input = input.cuda(non_blocking=True)\n",
        "                target = target.cuda(non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(acc1[0], input.size(0))\n",
        "            top5.update(acc5[0], input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.print(i)\n",
        "\n",
        "            end = time.time()\n",
        "\n",
        "        print(\n",
        "            \"====> Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\".format(\n",
        "                top1=top1, top5=top5\n",
        "            )\n",
        "        )\n",
        "        total_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return top1.avg, top5.avg, loss.item()\n",
        "\n",
        "\n",
        "def print_results(train_time, validate_time):\n",
        "\n",
        "    avg_train_time = train_time / (args.epochs - start_epoch)\n",
        "    avg_valid_time = validate_time / (args.epochs - start_epoch)\n",
        "    total_train_time = train_time + validate_time\n",
        "    print(\n",
        "        \"====> average training time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_train_time // 60), avg_train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> average validation time per epoch: {:,}m {:.2f}s\".format(\n",
        "            int(avg_valid_time // 60), avg_valid_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> training time: {}h {}m {:.2f}s\".format(\n",
        "            int(train_time // 3600), int((train_time % 3600) // 60), train_time % 60\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> validation time: {}h {}m {:.2f}s\".format(\n",
        "            int(validate_time // 3600),\n",
        "            int((validate_time % 3600) // 60),\n",
        "            validate_time % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"====> total training time: {}h {}m {:.2f}s\".format(\n",
        "            int(total_train_time // 3600),\n",
        "            int((total_train_time % 3600) // 60),\n",
        "            total_train_time % 60,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    main()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"====> total time: {}h {}m {:.2f}s\".format(\n",
        "            int(elapsed_time // 3600),\n",
        "            int((elapsed_time % 3600) // 60),\n",
        "            elapsed_time % 60,\n",
        "        )\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: mobilenetv1_20200415\n",
            "\n",
            "==> Load data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "==> Epoch: 0, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [0][  0/196]\tTime  2.758 ( 2.758)\tData  0.081 ( 0.081)\tLoss 4.6038e+00 (4.6038e+00)\tAcc@1   1.95 (  1.95)\tAcc@5   5.86 (  5.86)\n",
            "Epoch: [0][ 50/196]\tTime  0.110 ( 0.157)\tData  0.075 ( 0.070)\tLoss 4.5755e+00 (4.9203e+00)\tAcc@1   1.95 (  1.45)\tAcc@5   8.59 (  6.46)\n",
            "Epoch: [0][100/196]\tTime  0.105 ( 0.133)\tData  0.070 ( 0.072)\tLoss 4.4348e+00 (4.7542e+00)\tAcc@1   1.95 (  2.06)\tAcc@5  10.55 (  8.74)\n",
            "Epoch: [0][150/196]\tTime  0.111 ( 0.125)\tData  0.076 ( 0.073)\tLoss 4.3560e+00 (4.6243e+00)\tAcc@1   1.95 (  2.59)\tAcc@5  13.67 ( 10.88)\n",
            "====> Acc@1 3.146 Acc@5 12.966\n",
            "====> Epoch loss 4.520\n",
            "====> 35.33 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.694 ( 0.694)\tLoss 6.6242e+00 (6.6242e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   5.08 (  5.08)\n",
            "====> Acc@1 1.000 Acc@5 5.000\n",
            "====> 3.84 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 1, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [1][  0/196]\tTime  0.120 ( 0.120)\tData  0.078 ( 0.078)\tLoss 4.1231e+00 (4.1231e+00)\tAcc@1   7.42 (  7.42)\tAcc@5  21.48 ( 21.48)\n",
            "Epoch: [1][ 50/196]\tTime  0.111 ( 0.108)\tData  0.074 ( 0.073)\tLoss 4.0187e+00 (4.0844e+00)\tAcc@1   5.47 (  5.89)\tAcc@5  23.44 ( 22.00)\n",
            "Epoch: [1][100/196]\tTime  0.113 ( 0.108)\tData  0.078 ( 0.073)\tLoss 3.9482e+00 (4.0558e+00)\tAcc@1   7.03 (  6.03)\tAcc@5  29.69 ( 22.97)\n",
            "Epoch: [1][150/196]\tTime  0.110 ( 0.110)\tData  0.075 ( 0.074)\tLoss 3.8915e+00 (4.0164e+00)\tAcc@1  10.94 (  6.58)\tAcc@5  30.47 ( 24.24)\n",
            "====> Acc@1 6.938 Acc@5 25.290\n",
            "====> Epoch loss 3.988\n",
            "====> 31.83 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.075 ( 0.075)\tLoss 7.5455e+00 (7.5455e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   5.47 (  5.47)\n",
            "====> Acc@1 1.000 Acc@5 5.000\n",
            "====> 2.78 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 2, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [2][  0/196]\tTime  0.109 ( 0.109)\tData  0.074 ( 0.074)\tLoss 3.8786e+00 (3.8786e+00)\tAcc@1   8.59 (  8.59)\tAcc@5  34.38 ( 34.38)\n",
            "Epoch: [2][ 50/196]\tTime  0.106 ( 0.110)\tData  0.071 ( 0.074)\tLoss 3.9180e+00 (3.8241e+00)\tAcc@1   8.20 (  9.67)\tAcc@5  28.52 ( 30.88)\n",
            "Epoch: [2][100/196]\tTime  0.120 ( 0.110)\tData  0.074 ( 0.074)\tLoss 3.7083e+00 (3.8018e+00)\tAcc@1  10.94 (  9.70)\tAcc@5  37.50 ( 31.92)\n",
            "Epoch: [2][150/196]\tTime  0.107 ( 0.110)\tData  0.073 ( 0.074)\tLoss 3.8536e+00 (3.7761e+00)\tAcc@1  12.50 ( 10.30)\tAcc@5  33.59 ( 32.72)\n",
            "====> Acc@1 10.606 Acc@5 33.396\n",
            "====> Epoch loss 3.759\n",
            "====> 31.85 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.073 ( 0.073)\tLoss 8.7256e+00 (8.7256e+00)\tAcc@1   1.17 (  1.17)\tAcc@5   5.47 (  5.47)\n",
            "====> Acc@1 1.000 Acc@5 5.000\n",
            "====> 2.78 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 3, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [3][  0/196]\tTime  0.134 ( 0.134)\tData  0.092 ( 0.092)\tLoss 3.6725e+00 (3.6725e+00)\tAcc@1  12.11 ( 12.11)\tAcc@5  36.72 ( 36.72)\n",
            "Epoch: [3][ 50/196]\tTime  0.110 ( 0.113)\tData  0.076 ( 0.076)\tLoss 3.6421e+00 (3.6751e+00)\tAcc@1  12.50 ( 11.72)\tAcc@5  37.89 ( 35.84)\n",
            "Epoch: [3][100/196]\tTime  0.104 ( 0.113)\tData  0.069 ( 0.077)\tLoss 3.4064e+00 (3.6308e+00)\tAcc@1  13.28 ( 12.45)\tAcc@5  40.62 ( 37.18)\n",
            "Epoch: [3][150/196]\tTime  0.106 ( 0.113)\tData  0.070 ( 0.077)\tLoss 3.6972e+00 (3.6011e+00)\tAcc@1  11.33 ( 12.89)\tAcc@5  37.50 ( 38.13)\n",
            "====> Acc@1 13.304 Acc@5 38.904\n",
            "====> Epoch loss 3.577\n",
            "====> 32.25 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.074 ( 0.074)\tLoss 7.9688e+00 (7.9688e+00)\tAcc@1   1.17 (  1.17)\tAcc@5   4.69 (  4.69)\n",
            "====> Acc@1 1.000 Acc@5 5.160\n",
            "====> 2.94 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 4, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [4][  0/196]\tTime  0.109 ( 0.109)\tData  0.075 ( 0.075)\tLoss 3.4431e+00 (3.4431e+00)\tAcc@1  18.75 ( 18.75)\tAcc@5  42.58 ( 42.58)\n",
            "Epoch: [4][ 50/196]\tTime  0.109 ( 0.110)\tData  0.074 ( 0.074)\tLoss 3.3230e+00 (3.4291e+00)\tAcc@1  18.36 ( 15.72)\tAcc@5  51.56 ( 42.91)\n",
            "Epoch: [4][100/196]\tTime  0.111 ( 0.111)\tData  0.076 ( 0.075)\tLoss 3.3959e+00 (3.4364e+00)\tAcc@1  21.09 ( 15.77)\tAcc@5  43.36 ( 43.08)\n",
            "Epoch: [4][150/196]\tTime  0.135 ( 0.112)\tData  0.094 ( 0.076)\tLoss 3.2143e+00 (3.4293e+00)\tAcc@1  18.75 ( 15.96)\tAcc@5  46.09 ( 43.41)\n",
            "====> Acc@1 15.934 Acc@5 43.442\n",
            "====> Epoch loss 3.428\n",
            "====> 32.13 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.075 ( 0.075)\tLoss 8.9220e+00 (8.9220e+00)\tAcc@1   1.17 (  1.17)\tAcc@5   5.47 (  5.47)\n",
            "====> Acc@1 1.000 Acc@5 5.000\n",
            "====> 2.87 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 5, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [5][  0/196]\tTime  0.107 ( 0.107)\tData  0.072 ( 0.072)\tLoss 3.4002e+00 (3.4002e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  46.09 ( 46.09)\n",
            "Epoch: [5][ 50/196]\tTime  0.105 ( 0.110)\tData  0.070 ( 0.075)\tLoss 3.3538e+00 (3.3338e+00)\tAcc@1  14.84 ( 17.32)\tAcc@5  44.92 ( 45.88)\n",
            "Epoch: [5][100/196]\tTime  0.109 ( 0.112)\tData  0.073 ( 0.076)\tLoss 3.3339e+00 (3.3119e+00)\tAcc@1  16.41 ( 17.96)\tAcc@5  46.88 ( 46.53)\n",
            "Epoch: [5][150/196]\tTime  0.107 ( 0.111)\tData  0.072 ( 0.075)\tLoss 3.0698e+00 (3.3107e+00)\tAcc@1  23.44 ( 17.96)\tAcc@5  56.25 ( 46.57)\n",
            "====> Acc@1 18.008 Acc@5 46.634\n",
            "====> Epoch loss 3.307\n",
            "====> 31.93 seconds to train this epoch\n",
            "\n",
            "===> [ Validation ]\n",
            "Test: [ 0/40]\tTime  0.081 ( 0.081)\tLoss 8.9474e+00 (8.9474e+00)\tAcc@1   1.17 (  1.17)\tAcc@5   5.08 (  5.08)\n",
            "====> Acc@1 1.000 Acc@5 5.000\n",
            "====> 2.86 seconds to validate this epoch\n",
            "\n",
            "\n",
            "==> Epoch: 6, lr = 0.1\n",
            "===> [ Training ]\n",
            "Epoch: [6][  0/196]\tTime  0.110 ( 0.110)\tData  0.076 ( 0.076)\tLoss 3.4452e+00 (3.4452e+00)\tAcc@1  12.89 ( 12.89)\tAcc@5  42.97 ( 42.97)\n",
            "Epoch: [6][ 50/196]\tTime  0.106 ( 0.110)\tData  0.072 ( 0.074)\tLoss 3.2378e+00 (3.3593e+00)\tAcc@1  19.14 ( 17.16)\tAcc@5  47.66 ( 45.69)\n",
            "Epoch: [6][100/196]\tTime  0.103 ( 0.111)\tData  0.068 ( 0.076)\tLoss 3.2374e+00 (3.3022e+00)\tAcc@1  19.14 ( 18.15)\tAcc@5  50.78 ( 47.25)\n",
            "Epoch: [6][150/196]\tTime  0.108 ( 0.112)\tData  0.073 ( 0.076)\tLoss 3.2546e+00 (3.2716e+00)\tAcc@1  24.22 ( 18.67)\tAcc@5  51.56 ( 47.93)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0ee021852eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     print(\n",
            "\u001b[0;32m<ipython-input-48-0ee021852eb9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-0ee021852eb9>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_time, acc1_train, acc5_train, avgloss_train, train_loader, epoch, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     acc1_train, acc5_train, avgloss_train = train(\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-0ee021852eb9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPadded\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(image, border, fill)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpaste\u001b[0;34m(self, im, box, mask)\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_mutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}